{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcba9c38-ce3e-486a-8d3a-96e3a37b70ea",
   "metadata": {},
   "source": [
    "# Baseline RAG example\n",
    "\n",
    "This is a simple example of a baseline RAG application which purpose is to answer questions about the fantasy series [Malazan Universe](https://malazan.fandom.com/wiki/Malazan_Wiki) created by Steven Erikson and Ian C. Esslemont.\n",
    "\n",
    "First the example will show each step of a baseline RAG pipeline including **Indexing**, **Retrieval** and **Generation**. This is done in order to show the architecture without the abstraction provided by frameworks like LlamaIndex and LangChain.\n",
    "Then a more \"normal\" example will be shown using LlamaIndex.\n",
    "\n",
    "As a vector database, we will use [ChromaDB](https://docs.trychroma.com/), but this can easily be exchanged with other databases.\n",
    "\n",
    "In this example, we will use the following technologies\n",
    "\n",
    "- OpenAI API\n",
    "- ChromaDB\n",
    "- LlamaIndex\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae217db9-221f-4811-9101-c87d3db2c821",
   "metadata": {},
   "source": [
    "### Setup libraries and environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8edf740a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install chromadb llama-index-vector-stores-chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7a26f5a-d799-4b80-93e5-60579a74852e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     c:\\Users\\jach\\AppData\\Local\\miniconda3\\envs\\advanced-\n",
      "[nltk_data]     rag-env\\Lib\\site-\n",
      "[nltk_data]     packages\\llama_index\\core\\_static/nltk_cache...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import chromadb\n",
    "import chromadb.utils.embedding_functions as embedding_functions\n",
    "from chromadb import Settings\n",
    "from IPython.display import Markdown, display\n",
    "from llama_index.core import PromptTemplate, SimpleDirectoryReader\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from openai import OpenAI, AzureOpenAI\n",
    "\n",
    "import importlib\n",
    "import util\n",
    "\n",
    "# Suppose you made some changes to util.py\n",
    "\n",
    "#importlib.reload(util.helpers)\n",
    "from util.helpers import create_and_save_md_files, get_malazan_pages, get_theoffice_pages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772c0dca-fd51-4348-9ada-8ca12d0139bc",
   "metadata": {},
   "source": [
    "### Environment variables\n",
    "\n",
    "For this example you need to use an OpenAI API key. Go to [your API keys](https://platform.openai.com/api-keys) in the OpenAI console to generate one.\n",
    "\n",
    "Then add the following to a `.env` file in the root of the project.\n",
    "\n",
    "```\n",
    "OPENAI_API_KEY=<YOUR_KEY_HERE>\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79b5d76d-dae0-4cfe-b9f1-1de2477b465a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "openai_client = AzureOpenAI(\n",
    "    api_key=OPENAI_API_KEY,  \n",
    "    api_version=\"2024-05-01-preview\", # https://learn.microsoft.com/en-us/azure/ai-services/openai/reference?WT.mc_id=AZ-MVP-5004796\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1224aade",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#openai_client = AzureOpenAI(api_key=OPENAI_API_KEY)\n",
    "#openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "#    api_key=OPENAI_API_KEY,\n",
    "#    model_name=\"text-embedding-3-small\"\n",
    "#)\n",
    "\n",
    "openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    model_name=\"text-embedding-3-small\", #\"text-embedding-ada-002\",\n",
    "    api_type=\"azure\"\n",
    ")\n",
    "\n",
    "chroma_client = chromadb.PersistentClient(\n",
    "    path=\"./data/seges-gpt-lands-2024-newembeds/chromadb\", settings=Settings(allow_reset=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae6f25f-66b0-4acb-8503-1b00c2868c20",
   "metadata": {},
   "source": [
    "## Indexing\n",
    "\n",
    "In this step, we will index the documents in our vector database. This will allow us to retrieve the most relevant documents when we ask a question.\n",
    "\n",
    "We will use ChromaDB as our vector database and 'text-embedding-3-small' from OpenAI as our embedding model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8534742",
   "metadata": {},
   "source": [
    "#### Fetch and process saved documents\n",
    "\n",
    "First we need to fetch the documents we saved earlier.\n",
    "\n",
    "Then we will process the documents in order to add them to our vector database.\n",
    "The `SimpleDirectoryReader` fetches each section of the markdown file\n",
    "Then each section is split in to smaller chunks of text and each chunk is embedded using the OpenAI API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "add2504e",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader('./data/docs_lands_test').load_data()\n",
    "\n",
    "text_splitter = SentenceSplitter(chunk_size=512, chunk_overlap=20)\n",
    "\n",
    "document_data = []\n",
    "\n",
    "for document in documents:\n",
    "    chunks = text_splitter.split_text(document.text)\n",
    "    for idx, chunk in enumerate(chunks):\n",
    "        embedding = openai_client.embeddings.create(\n",
    "            input=chunk, model=\"text-embedding-3-small\")#\"text-embedding-ada-002\")\n",
    "        document_data.append({\n",
    "            \"id\": f\"{document.id_}-{idx}\",\n",
    "            \"text\": chunk,\n",
    "            \"metadata\": document.metadata,\n",
    "            \"embedding\": embedding.data[0].embedding\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26077bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings dim 1536\n",
      "{'id': 'b7b42a4b-f80b-4462-8057-68baa3267065-0', 'text': 'LANDSFORSØGENE  2024\\nForsøg og undersøgelser i\\nDansk Landbrugsrådgivning\\nSamlet og udarbejdet af\\nSEGES Innovation P/S, Planter & Miljø\\nved chefkonsulent Jon Birger Pedersen\\nAktiviteterne er blandt andet støttet af:', 'metadata': {'page_label': '1', 'file_name': 'Landsforsøgene 2024.pdf', 'file_path': 'c:\\\\Users\\\\jach\\\\projekter\\\\ADVANCED-RAG-EXAMPLES\\\\data\\\\docs_lands_test\\\\Landsforsøgene 2024.pdf', 'file_type': 'application/pdf', 'file_size': 10628392, 'creation_date': '2024-12-19', 'last_modified_date': '2024-12-19'}, 'embedding': [0.0023039341904222965, 0.00349593092687428, 0.05882889777421951, 0.009601208381354809, -0.05897122621536255, 0.02993631921708584, -0.02157454937696457, -0.010763553902506828, 0.013260223902761936, -0.0036738410126417875, 0.046564970165491104, -0.003973322920501232, -0.004922175779938698, -0.028275825083255768, 0.01132100448012352, 0.006084521301090717, -0.024788789451122284, 0.008782822638750076, 0.006855464540421963, -0.005358055233955383, 0.04559239745140076, -0.011943689547479153, 0.033470798283815384, -0.020649418234825134, 0.06637228280305862, -0.05882889777421951, 0.02174059860408306, 0.0027338832151144743, 0.01605934090912342, -0.009423298761248589, 0.06921884417533875, -0.0167709793895483, -0.031739138066768646, -0.01577468402683735, 0.016735399141907692, -0.020839188247919083, 0.009749466553330421, -0.012062296271324158, -0.01870426908135414, 0.037622030824422836, -0.00206672097556293, 0.009921446442604065, -0.02986515499651432, -0.01629655435681343, 0.01601189747452736, 0.014564896933734417, 0.01023575384169817, 0.004370654933154583, -0.0023128297179937363, 0.02026987634599209, 0.02981771156191826, -0.01577468402683735, -0.00011360293137840927, -0.008806543424725533, -0.017304711043834686, -0.0027991170063614845, -0.007869550958275795, -0.013924420811235905, -0.016355857253074646, 0.05659909173846245, 0.002979992190375924, 0.030007481575012207, 0.054701387882232666, 0.001740552601404488, -0.008498166687786579, 0.029960040003061295, -0.011967411264777184, 0.05788004398345947, 0.012726493179798126, -0.017933325842022896, 0.01534770056605339, 0.012299509719014168, -0.036507125943899155, -0.07040490955114365, -0.02421947754919529, -0.0015507818898186088, 0.008510027080774307, 0.013651625253260136, -0.05356276407837868, -0.011315074749290943, -0.00931062176823616, -0.016189808025956154, -0.06447457522153854, 0.0165693499147892, -0.04110906645655632, -0.04677846282720566, -0.04464354366064072, -0.01043145451694727, -0.042627230286598206, 0.03247449919581413, 0.013141617178916931, 9.103986667469144e-05, -0.04075324535369873, 0.022392936050891876, 0.02055453322827816, -0.021313615143299103, 0.02047150768339634, -0.009120851755142212, 0.01493257749825716, 0.04511797055602074, 0.05693119019269943, -0.005601198878139257, 0.0339215025305748, -0.02611718513071537, 0.012667190283536911, 0.009298761375248432, -0.019783589988946915, -0.014149772934615612, 0.06722624599933624, -0.02296224795281887, -0.05493859946727753, 0.0005589338252320886, 0.02035290189087391, 0.012429976835846901, -0.008148277178406715, -0.050004564225673676, -0.08193347603082657, -0.049055710434913635, 0.01552561018615961, -0.008000018075108528, -0.04582960903644562, 0.06732113659381866, 0.002117128809913993, 0.04919803887605667, 0.04051603004336357, 0.0433863140642643, 0.01374651025980711, -0.0072468663565814495, -0.0020118653774261475, 0.015928873792290688, 0.023460395634174347, -0.0031223201658576727, -0.008652355521917343, -0.006244640331715345, -0.018336588516831398, -0.02193037047982216, -0.03752714395523071, 0.01806379295885563, 0.023958543315529823, -0.02848931774497032, 0.040255095809698105, 0.0698355957865715, 0.0276116281747818, 0.051143188029527664, -0.01556119229644537, -0.03562943637371063, -0.032047517597675323, -0.0019199451198801398, 0.04938780888915062, 0.03949601575732231, -0.03790668398141861, -0.009470741264522076, -0.039069030433893204, 0.03105122037231922, 0.03259310871362686, -0.030908893793821335, -0.037622030824422836, 0.03750342130661011, 0.00027613111888058484, -0.006724996957927942, 0.0007746496703475714, 0.016308413818478584, 0.021408500149846077, 0.0017776171443983912, 0.0036471544299274683, 0.0039762877859175205, 0.0025900728069245815, -0.026923708617687225, -0.09037826955318451, -0.00316086714155972, -0.02587997168302536, -0.021467803046107292, 0.009559695608913898, 0.011030418798327446, -0.04839151352643967, 0.009755397215485573, 0.01293998584151268, 0.009832491166889668, 0.035368502140045166, -0.034490812569856644, 0.0022134967148303986, -0.016106782481074333, 0.03427732363343239, 0.0042075710371136665, 0.007839899510145187, 0.030268417671322823, 0.013663485646247864, 0.004287630319595337, 0.02950933389365673, 0.014066748321056366, -0.02197781205177307, -0.03515500947833061, 0.09773188084363937, 0.0015018567210063338, 0.0042846654541790485, 0.014730946160852909, -0.03285404294729233, 0.009263179264962673, 0.020993376150727272, 0.024361805990338326, -0.02362644486129284, -0.01108379103243351, -0.005366950761526823, -0.03961462154984474, 0.005773178767412901, 0.010579713620245457, -0.030244695022702217, 0.006719066761434078, -0.017897743731737137, -0.006063764914870262, 0.053752534091472626, 0.03396894410252571, 0.012667190283536911, 0.015063044615089893, -0.0011074895737692714, 0.014173494651913643, -0.05261391028761864, -0.0062209186144173145, 0.016782840713858604, 0.05218692496418953, -0.02737441472709179, -0.012513001449406147, 0.03069540113210678, 0.01692516915500164, 0.01751820184290409, 0.046493805944919586, 0.01469536405056715, -0.056077223271131516, 0.007561173755675554, -0.0935094803571701, 6.287079304456711e-05, 0.020601974800229073, -0.029770269989967346, 0.01335510890930891, 0.0015507818898186088, 0.004260943736881018, 0.01862124353647232, 0.017103079706430435, 0.006051904521882534, -0.011872525326907635, 0.02067313902080059, 0.014505593106150627, -0.00909119937568903, -0.018289145082235336, 0.011937758885324001, 0.03375545144081116, -0.0008043013513088226, -0.037693195044994354, 0.013189059682190418, -0.00846258457750082, -0.022630149498581886, 0.037764355540275574, 0.04070580378174782, -0.035131290555000305, 0.029438169673085213, -0.01945148967206478, -0.017328431829810143, -0.03797784820199013, -0.01138030830770731, -0.005989635828882456, -0.03648340702056885, 0.008687936700880527, -0.014778388664126396, -0.0024699834175407887, -0.03230845183134079, -0.0025426300708204508, 0.01763680949807167, 0.047513823956251144, -0.03363684564828873, -0.05052643269300461, 0.04082440957427025, -0.020566392689943314, 0.014600479044020176, 0.008124555461108685, -0.06063171848654747, 0.021550828590989113, 0.042817000299692154, 0.02654416859149933, -0.03408754989504814, 0.008907359093427658, -0.02425505965948105, 0.02260642684996128, -0.031074943020939827, -0.0386657677590847, -0.016782840713858604, 0.012762075290083885, 0.014719084836542606, 0.031976353377103806, -0.004382515791803598, 0.014813970774412155, 0.05650420859456062, -0.025452986359596252, 0.06874441355466843, -0.00456635607406497, 0.021669434383511543, -0.0017301745247095823, 0.004717579577118158, -0.010538200847804546, 0.011332865804433823, 0.019676843658089638, 0.019890334457159042, 0.025026002898812294, 0.03434848412871361, -0.029461892321705818, -0.03259310871362686, 0.0046671717427670956, -0.022416656836867332, -0.024314362555742264, -0.004969618748873472, -0.03434848412871361, -0.016308413818478584, 0.006422549951821566, -0.03553455322980881, -0.04957757890224457, 0.08027298003435135, -0.0378592424094677, 0.08833823353052139, 0.026093462482094765, 0.012536723166704178, -0.03361312299966812, -0.012358812615275383, -0.03750342130661011, 0.02856048196554184, -0.0315730907022953, 0.01136251725256443, -0.025239495560526848, -0.018846597522497177, 0.0009043756872415543, 0.04630403593182564, 0.011018557474017143, -0.0073239607736468315, 0.04556867480278015, -0.009417368099093437, -0.024551576003432274, 4.893682330475713e-07, 0.015074905008077621, -0.023258764296770096, -0.025500429794192314, 0.04986223578453064, -0.026283234357833862, -0.016616791486740112, 0.013580461032688618, 0.01552561018615961, -0.028750251978635788, -0.01964126154780388, 0.038594603538513184, -0.014659781940281391, -0.008948871865868568, 0.016166087239980698, 0.026259511709213257, 0.02402970753610134, -0.040610916912555695, 0.009020036086440086, 0.010745762847363949, -0.02934328466653824, -0.0181468166410923, 0.01645074225962162, 0.023424813523888588, -0.016308413818478584, 0.008610842749476433, -0.017802858725190163, -0.006920698098838329, 0.058876339346170425, 0.0410379022359848, -0.03451453521847725, -0.00366791058331728, -0.047205448150634766, 0.010063773952424526, 0.041559770703315735, -0.04606682434678078, 0.03854716196656227, 0.015418864786624908, -0.0280148908495903, -0.004210535902529955, -0.032687991857528687, -0.014303961768746376, -0.006191267166286707, 0.04051603004336357, -0.001998522086068988, 0.023128297179937363, 0.012103809043765068, 0.014066748321056366, -0.05275623872876167, -0.06836487352848053, 0.013319526799023151, 0.05085853114724159, -0.01130321342498064, -0.016474463045597076, -0.04990967735648155, 0.006149754859507084, -0.034016385674476624, -0.005871029105037451, 0.01751820184290409, -0.015418864786624908, -0.008314326405525208, -0.021918509155511856, 0.004358794540166855, 0.011570078320801258, -0.015513749793171883, -0.04896082356572151, -0.04314909875392914, -0.005103051196783781, -0.018431473523378372, 0.02587997168302536, -0.008231301791965961, 0.01940404810011387, -0.009506323374807835, 0.044358886778354645, -0.00023925185087136924, -0.01739959605038166, -0.03541594743728638, -0.06020473688840866, -0.0047294399701058865, -0.01228764932602644, 0.031193548813462257, -0.020993376150727272, -0.029556777328252792, 0.008071182295680046, -0.013070452958345413, -0.005607129540294409, 0.025690199807286263, 0.0012320266105234623, 0.03278287872672081, -0.04516541212797165, -0.01293998584151268, -0.039353687316179276, 0.03681550547480583, -0.018846597522497177, 0.026496725156903267, -0.06357316672801971, -0.04573472589254379, 0.004180884454399347, 0.027516743168234825, -0.009020036086440086, -0.029011186212301254, 0.010105286724865437, -0.011866595596075058, -0.037764355540275574, 0.01181322243064642, 0.02576136402785778, 0.030742844566702843, 0.029200958088040352, -0.003964427392929792, -0.004269839264452457, -0.008474444970488548, -0.035605717450380325, -0.028607923537492752, 0.016510045155882835, -0.013639764860272408, -0.03615130856633186, -0.031264711171388626, 0.01532397884875536, 0.015157929621636868, 0.018763571977615356, -0.03612758591771126, 0.017530063167214394, 0.015490028075873852, 0.007590825669467449, 0.013936281204223633, 0.032521944493055344, 0.0761454701423645, 0.036791782826185226, 0.023804355412721634, 0.02040034346282482, -0.02111198380589485, 0.014553035609424114, -0.015501889400184155, 0.0489133819937706, -0.032213564962148666, 0.004800604190677404, 0.041986752301454544, 0.03534478321671486, -0.08103206008672714, 5.0732141971820965e-05, -0.00074944575317204, 0.010300987400114536, -0.031501926481723785, -0.024527855217456818, -0.04594821482896805, -0.02777767740190029, -0.01739959605038166, -0.02981771156191826, -0.015833986923098564, 0.041393719613552094, 0.040848128497600555, 0.029295843094587326, 0.01066866796463728, 0.0230808537453413, -0.01633213646709919, -0.02820466086268425, 0.0500994473695755, 0.004050416871905327, 0.053467877209186554, -0.010739832185208797, 0.016830284148454666, -0.05356276407837868, -0.003454418620094657, 0.03615130856633186, -0.020127547904849052, -0.0050022355280816555, -0.005704979877918959, 0.025476709008216858, -0.011018557474017143, 0.027801398187875748, 0.03479919210076332, 0.0054974183440208435, -0.05085853114724159, -0.02062569558620453, 0.012679050676524639, -0.01909567043185234, 0.002693853573873639, 0.0449756421148777, -0.019748007878661156, -0.010336569510400295, 0.028892580419778824, 0.03261682763695717, 0.031335875391960144, -0.005998531356453896, 0.01516979094594717, -0.0017538958927616477, 0.010123077780008316, -0.015952594578266144, -0.012091947719454765, 0.003664945485070348, -0.004560425877571106, -0.004744266159832478, -2.3570755729451776e-05, -0.04082440957427025, 0.0002616759156808257, -0.04708683863282204, 0.005313578061759472, 0.013106035068631172, 0.0022268397733569145, 0.00804746150970459, -0.0026078636292368174, 0.024409249424934387, -0.00014909225865267217, 0.003318021073937416, -0.011119373142719269, -0.019143113866448402, 0.025192052125930786, 0.017565645277500153, -0.010063773952424526, -0.017186103388667107, -0.015418864786624908, -0.016498185694217682, -0.023875517770648003, 0.023958543315529823, -0.0045426348224282265, -0.03482291102409363, 0.02934328466653824, -0.0012335091596469283, 0.0009184602531604469, 0.00446850573644042, -0.016189808025956154, 0.04545006901025772, -0.02974654734134674, -0.005449975375086069, -0.028536759316921234, 0.04753754660487175, 0.002004452282562852, 0.009257248602807522, 0.036744341254234314, -0.028418153524398804, 0.012868821620941162, 0.004628624301403761, 0.004518913570791483, 0.004865837749093771, -0.016854004934430122, 0.02915351465344429, 0.019866613671183586, -0.022499682381749153, 0.04791708663105965, 0.020103827118873596, 0.028631646186113358, 0.009868073277175426, -0.0048065343871712685, -0.03622246906161308, -0.014730946160852909, -0.03534478321671486, 0.0072112842462956905, -0.006446271203458309, 0.003940706141293049, 0.026733938604593277, -0.042864441871643066, -0.01822984218597412, -0.006238709669560194, -0.0013928868575021625, 0.03641224279999733, -0.06091637536883354, -0.014209076762199402, 0.03612758591771126, 0.043528638780117035, -0.024622740224003792, 0.03396894410252571, -0.022618288174271584, 0.011243910528719425, 0.016854004934430122, -0.012429976835846901, 0.0008139381534419954, -0.008575260639190674, 0.00016873648564796895, -0.00465531088411808, -0.007899203337728977, -0.007389194332063198, -0.03783551976084709, -0.03740853816270828, -0.04630403593182564, 0.03164425492286682, -0.017494481056928635, -0.006511505227535963, 0.016272831708192825, 0.001253523980267346, 0.0021808797027915716, -0.008925150148570538, -0.010318778455257416, -0.007656059227883816, 0.010484827682375908, 0.01090588141232729, -0.028228383511304855, 0.017767276614904404, -0.011730197817087173, 0.05859168618917465, -0.00844479352235794, 0.02338923141360283, -0.008041530847549438, -0.04386074095964432, 0.04359980300068855, -0.02974654734134674, 0.00047553854528814554, 0.027398135513067245, -0.057026077061891556, 0.013876978307962418, 0.035724323242902756, -0.002819873159751296, -0.00423129228875041, 0.01445815060287714, -0.00960713904350996, -0.021313615143299103, -0.03230845183134079, 0.039946720004081726, -0.009014105424284935, 0.05413207411766052, -0.020696859806776047, 0.0002911422634497285, -0.02725580893456936, 0.013912560418248177, -0.027872562408447266, 0.008035600185394287, 0.029414448887109756, -0.02433808520436287, -0.0347043052315712, -0.019664982333779335, 0.02872653119266033, 0.0073654730804264545, 0.01783844083547592, -0.011190537363290787, -0.02706603705883026, -0.03484663367271423, -0.03373173251748085, -0.044524937868118286, 0.036317355930805206, -0.0017346222884953022, -0.011445541866123676, -0.010982975363731384, 0.006606390234082937, 0.008083043619990349, 0.02540554478764534, 0.006464062258601189, 0.021752459928393364, -0.0049963053315877914, 0.01798076741397381, 0.02516833133995533, 0.03873693197965622, 0.006659763399511576, -0.008533748798072338, -0.024527855217456818, -0.022155722603201866, 0.05493859946727753, 0.05218692496418953, -0.0019303231965750456, -0.004815429914742708, -0.028062334284186363, 0.011137164197862148, -0.01556119229644537, 0.021598270162940025, 0.03045818768441677, 0.005737596657127142, 0.010621225461363792, 0.02998376078903675, -0.008373629301786423, -0.015667937695980072, 0.0339215025305748, -0.03515500947833061, 0.019546376541256905, 0.006867324933409691, 0.02754046395421028, 0.03033958189189434, -0.037455979734659195, -0.10816926509141922, 0.013580461032688618, -0.02618834748864174, -0.0007090453873388469, -0.030315859243273735, -0.047798480838537216, -0.056788865476846695, -0.025144610553979874, 0.008533748798072338, 0.028940021991729736, -0.009713884443044662, -0.008166068233549595, -0.028465595096349716, -0.0481305792927742, 0.040017884224653244, 0.016937030479311943, -9.95183945633471e-05, -0.031146105378866196, 0.01490885578095913, 0.004939966835081577, -0.016166087239980698, -0.015964455902576447, -0.01841961219906807, 0.0021008201874792576, 0.012263927608728409, 0.003484070301055908, 0.02718464471399784, 0.0009199428022839129, 0.0054262541234493256, 0.016462603583931923, 0.009144572541117668, 0.024207618087530136, 0.00962493009865284, -0.008171997964382172, 0.031193548813462257, -0.03949601575732231, 0.003961462061852217, -0.01154042687267065, -0.005203866865485907, 0.0056782932952046394, -0.016201667487621307, 0.021361056715250015, -0.029533056542277336, 0.002628619782626629, 0.008391420356929302, -0.01002226211130619, 0.00978504866361618, 0.010223893448710442, 0.01767239160835743, -0.027113480493426323, -0.001491478644311428, -0.018514497205615044, 0.007638268172740936, -0.02635439671576023, -0.012418116442859173, 0.0258325282484293, -0.004598972853273153, -0.021610131487250328, 0.002535217208787799, 0.03766947239637375, 0.01428024098277092, 0.014825831167399883, -0.011937758885324001, 0.02040034346282482, 0.0009251318406313658, -0.0005985929165035486, 0.014019305817782879, -0.03105122037231922, -0.016201667487621307, -0.001114902552217245, 0.012091947719454765, -0.029319563880562782, 0.006677554454654455, -0.01684214361011982, 0.007531522307544947, 0.014090470038354397, -0.03873693197965622, 0.03349451720714569, -0.001571538159623742, 0.0033773244358599186, 0.021562688052654266, 0.04314909875392914, -0.028394432738423347, -0.012240205891430378, 0.039353687316179276, -0.017257267609238625, -0.0001518721110187471, 0.030481908470392227, -0.0018962238682433963, -0.022582706063985825, -0.05973030999302864, 0.02082732692360878, 0.02299783006310463, -0.007733153644949198, 0.05413207411766052, -0.012987428344786167, 0.031146105378866196, -0.011570078320801258, 0.012809517793357372, 0.009464810602366924, -0.010603434406220913, -0.0031312154605984688, -0.03128843382000923, 0.018526358529925346, -0.0010044500231742859, 0.04170209914445877, 0.0031667975708842278, -0.005150493700057268, 0.04516541212797165, -0.042817000299692154, -0.007774665951728821, -0.045426346361637115, 0.011724267154932022, 0.007389194332063198, -0.006191267166286707, 0.007151980884373188, 0.0028465595096349716, 0.029438169673085213, -0.006167545914649963, -0.0030926684848964214, 0.004759091883897781, 0.053040895611047745, -0.01585770957171917, -0.02718464471399784, 0.012797657400369644, -0.04606682434678078, 0.03750342130661011, 0.003902158699929714, -0.006155685056000948, -0.016854004934430122, 0.008314326405525208, -0.0043943761847913265, -0.023412952199578285, -0.07372589409351349, -0.008290604688227177, 0.01821798086166382, -0.022464100271463394, -0.005871029105037451, -0.013936281204223633, 0.021278033033013344, 0.020898491144180298, 0.019083809107542038, 0.027564184740185738, -0.0022772476077079773, 0.02398226410150528, 0.005826551467180252, -0.006072660442441702, 0.022535262629389763, 0.03963834419846535, -0.04056347534060478, 0.018016349524259567, -0.029438169673085213, -0.02338923141360283, -0.0030541212763637304, 0.022143861278891563, -0.029888875782489777, -0.027991170063614845, -9.488531941315159e-05, -0.007015583571046591, 0.028133496642112732, 0.002837663982063532, 0.01731657050549984, -0.049767348915338516, 0.010828787460923195, -0.05038410425186157, 0.028987465426325798, -0.023531559854745865, -0.016948889940977097, -0.0232706256210804, 0.03309125453233719, -0.013971863314509392, 0.06262431293725967, -0.007519661448895931, 0.0070511652156710625, 0.006315804086625576, 0.0012727975845336914, 0.025666479021310806, -0.01889403909444809, 0.0007260951097123325, 0.00869979802519083, -0.03814389929175377, 0.008373629301786423, -0.010941463522613049, 0.04241373762488365, -0.007727223448455334, 0.04635147750377655, -0.014576757326722145, -0.013710929080843925, 0.006244640331715345, -0.0030155740678310394, 0.029200958088040352, -0.01246555894613266, -0.050431545823812485, -0.015549331903457642, 0.008539678528904915, -0.0191312525421381, 0.0004536704218480736, 0.004741300828754902, -0.034656863659620285, 0.039780668914318085, -0.036625731736421585, 0.0020904422271996737, -0.0024210582487285137, 0.0710216611623764, 0.010538200847804546, 0.0035819208715111017, -0.023068994283676147, 0.002575246850028634, 0.037930406630039215, 0.02647300437092781, 0.0433863140642643, 0.007418845780193806, -0.01493257749825716, -0.004492226988077164, -0.03999416157603264, 0.0011104547884315252, 0.025927413254976273, 0.007359542418271303, 0.045544952154159546, -0.0035404085647314787, -0.07310914248228073, 0.06490156054496765, 0.002252043690532446, -0.031810302287340164, 0.005974810104817152, -0.013948141597211361, -0.030505631119012833, 0.0021897752303630114, -0.04039742425084114, -0.012346952222287655, -0.005162354558706284, 0.026496725156903267, 0.012323230504989624, 0.0022994864266365767, 0.013616043142974377, 0.0024269886780530214, 0.009441088885068893, 0.009227597154676914, -0.009269109927117825, 0.017340291291475296, -0.021159427240490913, 0.011605660431087017, 0.006837673485279083, 0.026378119364380836, -0.01668795570731163, -0.008160137571394444, -0.03750342130661011, -0.023721329867839813, -0.02220316417515278, -0.004376585595309734, -0.006701275706291199, 0.03880809620022774, 0.012103809043765068, 0.04165465384721756, 0.01490885578095913, 0.015252815559506416, -0.031146105378866196, 0.01155821792781353, 0.023460395634174347, -0.030600516125559807, -0.028346989303827286, -0.00025908139650709927, -0.022630149498581886, 0.008510027080774307, -0.05550791323184967, -0.01941590942442417, 0.03242705762386322, 0.011522635817527771, -0.0029607184696942568, -0.028275825083255768, 0.006001496687531471, 0.012139390222728252, -0.0034722096752375364, -0.019048228859901428, 0.012667190283536911, -0.04445377364754677, -0.007952575571835041, -0.041322555392980576, -0.012091947719454765, -0.003320986172184348, -0.010271335951983929, 0.013070452958345413, 0.016818422824144363, -0.04943525046110153, -0.003318021073937416, 0.0005707945092581213, 0.013793953694403172, 0.0262357909232378, 0.007774665951728821, 0.07472218573093414, -0.012524861842393875, 0.004432923626154661, -0.0023602722212672234, -0.0024670183192938566, -0.016616791486740112, 0.01645074225962162, -0.016937030479311943, -0.03819134086370468, 0.01240625511854887, 0.025713922455906868, 0.01711493916809559, 0.03522617369890213, 0.029675383120775223, -0.012127529829740524, 0.014090470038354397, 0.005488522816449404, -0.07068956643342972, -0.0003784293367061764, -0.0004028919502161443, 0.03309125453233719, -0.024432970210909843, -0.03527361899614334, 0.012026714161038399, -0.013604182749986649, -0.022902943193912506, 0.007217214442789555, -0.03612758591771126, 0.008533748798072338, 0.027801398187875748, -0.01838403008878231, 0.015454446896910667, 0.010555991902947426, 0.014541175216436386, -0.008249092847108841, -0.009915515780448914, -0.004948862362653017, -0.05735817551612854, 0.016083061695098877, -0.013319526799023151, 0.010241684503853321, 0.008925150148570538, -0.0020148304756730795, 0.000542996043805033, -0.016711676493287086, 0.029248399659991264, -0.005936262663453817, -0.03565315902233124, -0.0017761345952749252, 0.004044486675411463, 0.015632355585694313, -0.009518183767795563, -0.004845081828534603, -0.00555375637486577, -0.00588882016018033, 0.02742185816168785, -0.011587869375944138, 0.008557469584047794, -0.022630149498581886, 0.0012238724157214165, 0.011593800038099289, 0.012726493179798126, 0.015074905008077621, -0.006849533878266811, -0.0022727998439222574, 0.0027976343408226967, -0.012975567951798439, 0.03672061860561371, -0.007863621227443218, -0.03022097423672676, 0.014730946160852909, 0.008806543424725533, 0.0005229812231846154, 0.035012684762477875, -0.001291329856030643, -0.01605934090912342, 0.023045271635055542, 0.010840647853910923, 0.003454418620094657, -3.741205728147179e-05, 0.009275039657950401, -0.005782074294984341, 0.008527818135917187, -0.00681395223364234, 0.05194971337914467, 0.030624236911535263, 0.0036441893316805363, 0.03968578577041626, -0.01645074225962162, -0.007193493191152811, 0.02296224795281887, 0.03880809620022774, 0.007602686062455177, 0.005829516798257828, -0.025500429794192314, 0.01869240775704384, -0.028536759316921234, 0.008865847252309322, 0.011481123976409435, -0.018953341990709305, 0.024361805990338326, 0.0031282503623515368, 0.0018517463468015194, -0.021349197253584862, 0.007252796553075314, 0.008776891976594925, 0.0020474472548812628, -0.0102594755589962, 0.0010911811841651797, 0.017684251070022583, 0.005989635828882456, -0.028062334284186363, 0.02564275823533535, 0.01069238968193531, -0.004880663473159075, 0.004598972853273153, -0.03420615941286087, 0.004616763908416033, -0.006707205902785063, -0.013283944688737392, 0.017458898946642876, 0.011967411264777184, -0.02362644486129284, -0.013865116983652115, 0.03460942208766937, -0.01353301852941513, 0.037574585527181625, 0.030031204223632812, -0.014268379658460617, -0.018561940640211105, -0.0018784328131005168, 0.011842873878777027, -0.027587907388806343, -0.02559531480073929, -0.011356586590409279, 0.015252815559506416, -0.0018858456751331687, 0.013521158136427402, -0.02374505065381527, -0.01798076741397381, -0.007703501731157303, -0.027896283194422722, -0.0012727975845336914, 0.010822856798768044, 0.035083845257759094, 0.013734649866819382, -0.01807565428316593, -0.021598270162940025, -0.012607886455953121, 0.0011779123451560736, 0.01755378395318985, -0.03940112888813019, -0.0003450712247285992, -0.003664945485070348, 0.0028836242854595184, -0.001377319684252143, -0.026923708617687225, -0.014315823093056679, 0.0037212837487459183, 0.07899203151464462, 0.027872562408447266, -0.013070452958345413, 0.028773972764611244, -0.004809499718248844, 0.0465412512421608, 0.01850263774394989, -0.0029251365922391415, -0.00838548969477415, 0.028180940076708794, 0.0433863140642643, -0.004302456043660641, 0.022464100271463394, -0.0012246136320754886, 0.035842929035425186, -0.008646424859762192, -0.030624236911535263, -0.020696859806776047, -0.01996149867773056, 0.02742185816168785, -0.014493732713162899, 0.062197327613830566, -0.010188311338424683, -0.010597503744065762, -0.0014625682961195707, -0.0195226538926363, 0.01996149867773056, -0.02903490699827671, 0.03705271705985069, -0.013212780468165874, 0.01968870311975479, 0.003315055975690484, -0.023329928517341614, -0.005292821675539017, -0.0064522018656134605, -0.008094904012978077, 0.0025055655278265476, -0.0012112704571336508, 0.024527855217456818, -0.03363684564828873, -0.05175994336605072, -0.007691641338169575, -0.00045515302917920053, -0.025666479021310806, -0.0027190574910491705, -0.009221667423844337, 0.005165319424122572, -0.058401916176080704, 0.014256519265472889, 0.011042279191315174, -0.02497856132686138, -0.008527818135917187, -0.010793205350637436, -0.011042279191315174, -0.028631646186113358, -0.03242705762386322, -0.01594073325395584, -0.029319563880562782, 0.0347043052315712, -0.040136490017175674, -0.0173521526157856, -0.0051208422519266605, 0.004204605706036091, 0.02606974169611931, 0.017020054161548615, -0.015679799020290375, -0.022831780835986137, 0.0030511561781167984, -0.0076441983692348, -0.02370946854352951, 0.014054887928068638, 0.0043943761847913265, -0.00019625693676061928, -0.009221667423844337, 0.014861413277685642, 0.04488075524568558, 0.05821214243769646, -0.014031167142093182, -0.03147820383310318, 0.05806981399655342, -0.023341787979006767, 0.03764574974775314, -0.016996333375573158, -0.03088517114520073, 0.004610833711922169, 0.011172746308147907, -0.01798076741397381, -0.0004318023275118321, -0.048771053552627563, 0.006203127559274435, -0.006054869387298822, -0.019071949645876884, 0.001706453156657517, 0.016000036150217056, -0.02040034346282482, 0.01668795570731163, -0.002210531383752823, -0.009162363596260548, -0.0026686496566981077, -0.024622740224003792, -0.01838403008878231, 0.004518913570791483, -0.0082846749573946, 0.002979992190375924, -0.01728098839521408, -0.016498185694217682, -0.026449283584952354, -0.014849552884697914, -0.007608616724610329, -0.020566392689943314, -0.03634107857942581, 0.0045129829086363316, -0.01138030830770731, -0.021515246480703354, -0.01798076741397381, 0.03854716196656227, -0.0022268397733569145, -0.036388520151376724, -0.004765022080391645, -0.01933288387954235, 0.002582659712061286, 0.022333631291985512, -0.02749302051961422, 0.004255013540387154, 0.029604218900203705, -0.007519661448895931, -0.01134472619742155, -0.0008947389433160424, 0.01865682564675808, 0.03164425492286682, 0.024290641769766808, 0.02433808520436287, 0.005275030620396137, -0.012809517793357372, 0.011979271657764912, 0.01940404810011387, 0.024243198335170746, -0.02647300437092781, 0.015063044615089893, -0.03380289673805237, 0.0030481908470392227, 0.009464810602366924, -0.004527808632701635, 0.012382534332573414, -0.0004325436311773956, -0.02355528064072132, -0.016474463045597076, -0.008118624798953533, 0.024124592542648315, 0.019700564444065094, 0.03812017664313316, -0.00614382466301322, -0.010662738233804703, 0.02245223894715309, 0.013141617178916931, 0.04241373762488365, 0.002324690343812108, 0.03750342130661011, -0.0054143937304615974, -0.009903655387461185, -0.026164626702666283, -0.007068956270813942, -0.019890334457159042, 0.017091218382120132, 0.014256519265472889, -0.02910607121884823, -0.013544879853725433, 0.031074943020939827, 0.01684214361011982, -0.01680656149983406, -0.01534770056605339, -0.018834736198186874, 0.013212780468165874, -0.00623277947306633, -0.00332395127043128, 0.018194260075688362, -0.04165465384721756, 0.04545006901025772, -0.018206121399998665, 0.012738354504108429, 0.0025974856689572334, -0.00864049419760704, 0.0063751074485480785, -0.006962210405617952, 0.0054974183440208435, 0.02245223894715309, 0.016972610726952553, -0.02047150768339634, 0.03214240074157715, -0.017802858725190163, 0.0025011177640408278, -0.03344707563519478, 0.026449283584952354, 0.013888838700950146, 0.011807291768491268, -0.01021796278655529, 0.004649380687624216, -0.013758371584117413, 0.00010943316738121212, 0.00843886286020279, 0.0004625659203156829, 0.018099375069141388, 0.005108981393277645, 0.01511048711836338, 0.031620532274246216, -0.014481872320175171, -0.010129007510840893, 0.010247614234685898, -0.0055033485405147076, -0.03112238459289074, 0.030244695022702217, -0.006345455534756184, 0.02098151668906212, 0.05175994336605072, 0.006238709669560194, -0.016320275142788887, -0.011641242541372776, 0.007353612221777439, 0.00980283971875906, -0.0058324821293354034, -0.014564896933734417, -0.002321725245565176, 0.003664945485070348, -0.041915591806173325, 0.008836195804178715, 0.012809517793357372, 0.02825210429728031, 0.014363265596330166, -0.01660493016242981, -0.008011879399418831, 0.026046020910143852, 0.02659161016345024, -0.007816177792847157, -0.0029607184696942568, -0.016462603583931923, -0.019902195781469345, -0.05104830116033554, -0.007448497693985701, 0.01728098839521408, 0.0028628678992390633, 0.005405498202890158, 0.001120832865126431, 0.017494481056928635, -0.006464062258601189, -0.01359232235699892, 0.022357353940606117, 0.013473715633153915, -0.006985931657254696, -0.007940715178847313, 0.014386986382305622, -0.042983051389455795, 0.01892962120473385, -0.02150338515639305, -0.041986752301454544, -0.01130321342498064, -0.004275769926607609, 0.008788752369582653, 0.007584895472973585, -0.028299545869231224, -0.00931062176823616, 0.013248362578451633, -0.04393190145492554, 0.017779136076569557, -0.016913307830691338, 0.004450714681297541, 0.02777767740190029, 0.007525592111051083, 0.005734631326049566, 0.0042846654541790485, 0.018407752737402916, 0.004951827693730593, -0.0013565635308623314, -0.0020874771289527416, -0.020293597131967545, -0.024409249424934387, -0.015015602111816406, 0.02642556093633175, 0.017613086849451065, 0.022464100271463394, -0.024041566997766495, 0.034063830971717834, -0.0347043052315712, 0.008160137571394444, -0.00018615684530232102, 0.0027249876875430346, -0.0038932631723582745, -0.0560297816991806, 0.0010133455507457256, 0.039069030433893204, 0.01199113205075264, -0.0038902980741113424, -0.0054736970923841, -0.0034603490494191647, -0.010555991902947426, -0.026046020910143852, 0.012044505216181278, 0.01692516915500164, 0.008622703142464161, 0.019143113866448402, 0.024954838678240776, -0.021289894357323647, 0.011048209853470325, 0.0029266190249472857, -0.006090451497584581, -0.002069686073809862, 0.027991170063614845, 0.04450121521949768, -0.031098663806915283, -0.029651662334799767, -0.0280148908495903, -0.021586410701274872, 0.0005441079847514629, -0.01882287487387657, -0.020246155560016632, 0.009168294258415699, 0.039780668914318085, 0.02998376078903675, -0.009464810602366924, -0.0023839937057346106, 0.02927212044596672, -0.01636771857738495, 0.002161606214940548, 0.012441837228834629, -0.026520447805523872, 0.07671478390693665, 0.018490776419639587, 0.015917012467980385, -0.020483369007706642, -0.005399567540735006, -0.03128843382000923, 0.022902943193912506, -0.007270587608218193, -0.03883181884884834, -0.0036708759143948555, -0.02425505965948105, 0.00013185723219066858, -0.004059312399476767, 0.009097130037844181, 0.024290641769766808, 0.0061794063076376915, -0.015335840173065662, 0.0006412172224372625, 0.04540262371301651, -0.005049678031355143, -0.01909567043185234, 0.020091965794563293, -0.019985221326351166, 0.027326971292495728, 0.024765068665146828, 0.021515246480703354, 0.02177618071436882, -0.0025515255983918905, 0.01139809936285019, 0.029177235439419746, -0.03105122037231922, 0.011866595596075058, 0.028845136985182762, 0.034894075244665146, 0.017020054161548615, 0.009850282222032547, -0.003899193601682782, 0.0010911811841651797, -0.0027249876875430346, 0.03802529349923134, 0.016854004934430122, 0.017494481056928635, -0.004287630319595337, 0.009678302332758904, 0.0017123834695667028, -0.026022298261523247, -0.010271335951983929, 0.023282485082745552, -0.02611718513071537, -0.019439630210399628, -0.005512244068086147, 0.019071949645876884, -0.025144610553979874, 0.016154225915670395, -0.04919803887605667, -0.018846597522497177, 0.02157454937696457, -0.016854004934430122, 0.030719121918082237, -0.0512855164706707, -0.02225060760974884, 0.05479627102613449, -0.01984289288520813, -0.019771728664636612, 0.010763553902506828]}\n"
     ]
    }
   ],
   "source": [
    "print(\"embeddings dim\", len(document_data[0]['embedding']))\n",
    "print(document_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9e5fcc",
   "metadata": {},
   "source": [
    "#### Add documents to ChromaDB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69311d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [doc[\"text\"] for doc in document_data]\n",
    "embeddings = [doc[\"embedding\"] for doc in document_data]\n",
    "metadatas = [doc[\"metadata\"] for doc in document_data]\n",
    "ids = [doc[\"id\"] for doc in document_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9d947dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client.reset()\n",
    "collection = chroma_client.get_or_create_collection(\n",
    "    name=\"lands2024new\", metadata={\"hnsw:space\": \"cosine\"}, embedding_function=openai_ef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d806a863",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(\n",
    "    embeddings=embeddings,\n",
    "    documents=documents,\n",
    "    metadatas=metadatas,\n",
    "    ids=ids)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9daf5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "# Initialize the PersistentClient again with the same path\n",
    "chroma_client_load = chromadb.PersistentClient(\n",
    "    path=\"./data/seges-gpt-lands-2024-newembeds/chromadb\",\n",
    "    settings=Settings(allow_reset=True)\n",
    ")\n",
    "\n",
    "# Get the existing collection by name\n",
    "collection_load = chroma_client_load.get_collection(name=\"lands2024new\", embedding_function=openai_ef)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026a9edc",
   "metadata": {},
   "source": [
    "## Retrieval\n",
    "\n",
    "In this step, we will retrieve the most relevant documents to a given question. We will use the vector database to retrieve the most similar documents to the question.\n",
    "\n",
    "In order to do this we will use the `text-embedding-3-small` model (**the same model used to index the documents**) from OpenAI to embed the question and then use the vector database to retrieve the most similar documents.\n",
    "\n",
    "We will retrieve the top 5 documents based on the _cosine similarity_ between the question and the documents. Other similarity metrics can be used as well like squared L2 or inner product.\n",
    "\n",
    "Change `cosine` to `l2` or `ip` when creating the collection above to try these out.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2223843a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hvilken brødhvedesort til høst i 2025?'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = [#\"Hvad står P, L, A, C og E for i PLACE-akronymet af John Ziman\",\n",
    "         \"hvilken brødhvedesort til høst i 2025?\",\n",
    "         ]\n",
    "\n",
    "query = queries[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fd8c8c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Collection(name=vtdat)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "156f5fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "221 KUL TURTEKNIK OG JORD  AFPRØVNING  AF FREMTIDENS   BÆREDYGTIGE  DYRKNINGS SYSTEMER\n",
       "rødderne i minirhizotron-rør i Slagelse og Holstebro samt \n",
       "infiltrationsmålinger på alle lokaliteter. Disse data vil bli -\n",
       "ve offentligt i en Landbrugsinfo-artikel i starten af 2025.\n",
       "I forsøgene tilstræbes det at behandle de forskellige \n",
       "forsøgsled ud fra et mål om at optimere alle dyrknings-\n",
       "systemerne. Såtid og udsædsmængde tilpasses jordens tjenlighed i de forskellige systemer, ligesom gødsknings- \n",
       "og planteværnsstrategi tilpasses aktuelle behov.\n",
       "I 2024 er de tre storskalaforsøg videreført på fjerde år. \n",
       "Forsøgene evaluerer som nævnt dyrkningssystemerne: \n",
       "traditionel pløjning, reduceret jordbearbejdning og CA. I første forsøgsår var afgrøden hestebønner, efterfulgt af \n",
       "vinterhvede med efterafgrøde i 2022 og vårbyg i 2023. I \n",
       "efteråret 2023 blev der sået vinterraps på alle lokaliteter. På grund af dårlig fremspiring ved Slagelse, blev der om-\n",
       "sået med vinterhvede. Ligeledes blev rapsen i Birkelse \n",
       "nedvisnet i foråret 2024 på grund af dårlig plantevækst. Her blev i stedet sået havre. Omsåningen skyldes de me -get våde forhold (se foto). Den dårlige plantevækst har \n",
       "ikke været påvirket af dyrkningssystemet.\n",
       "\n",
       "------------\n",
       "\n",
       "Her er det forsøget ved Esbjerg d. 1. maj 2024. \n",
       "Forsøget blev kasseret.FOTO: LEIF HAGELSKJÆR, SEGES INNOVATION\n",
       "STRATEGI\n",
       "Vælg altid en vinterhvedesort eller en \n",
       "sortsblanding, der:\n",
       " >har givet et stort udbytte gennem flere års for -\n",
       "søg\n",
       " >har en god overvintringsevne\n",
       " >har en god stråstivhed, så den kan dyrkes uden \n",
       "vækstregulering\n",
       " >har en effektiv resistens over for følgende syg -\n",
       "domme (i prioriteret rækkefølge):\n",
       " – Septoria\n",
       " – gulrust\n",
       " – meldug\n",
       " – brunrust.\n",
       "En satsning på deciderede brødhvedesorter er kun aktuel, hvis der er rimelig sikkerhed for afsætning til en passende merpris.\n",
       "\n",
       "------------\n",
       "\n",
       "Vårhvedesorter, der har dækket over 1,0 procent af \n",
       "udsædsproduktionen i 2024. T abellen viser sorternes andel af udsædsproduktionen i procent\n",
       "Høstår 2020 2021 2022 2023 2024\n",
       "T on i alt 3.347 4.704 4.768 2.621 2.777\n",
       "Kapitol 2 25 33 52 33\n",
       "Bravens 3 14 19\n",
       "KWS Fixum 10\n",
       "KWS Sharki 3 8 9\n",
       "Sonett 5 6 5 11 8\n",
       "Dacke 2 5 3 1 7\n",
       "Thorus 21 27 28 6 4\n",
       "KWS Barolum 4\n",
       "KWS T alisker 1 2 6 4 4\n",
       "Andre sorter 70 36 19 4 2\n",
       "\n",
       "------------\n",
       "\n",
       "Det er bemærkelsesværdigt, at vinterbyg har klaret sig \n",
       "godt i et klimamæssigt vanskeligt år.\n",
       "Der har været anlagt ti forsøg til høst 2024, hvoraf seks \n",
       "har givet brugbare resultater. T o af de kasserede forsøg \n",
       "har været vandlidende. I et forsøg har plantebestanden været for ringe og uens, og i det sidste forsøg har der væ -\n",
       "ret en uensartet plantebestand på langs af parcellerne i halvdelen af forsøget. I tabel 2 er resultaterne af lands -\n",
       "forsøgene opdelt på tre forsøg på Øerne og tre i Jylland. \n",
       "Udbytteniveauet er 21,9 hkg pr. ha højere på Øerne end \n",
       "i Jylland, og udbyttet varierer fra 74,6 hkg pr. ha i Nord-jylland til 117,0 hkg pr. ha på Lolland i målesortsblandin -\n",
       "gen. Det er en stor variation, som typisk ses i klimamæs-sigt udfordrende år, enten med tørke eller med megen nedbør. De mest dyrkede sorter til høst 2024 har været de toradede LG Globetrotter, Bordeaux, Alaska og Or -\n",
       "cade. LG Globetrotter og Bordeaux har ikke været med \n",
       "i Landsforsøgene i 2024, mens Alaska og Orcade har gi-\n",
       "vet forholdstal 98 og 97. Desuden har sortsblandinger udgjort 18 procent af den solgte udsæd. Sortsblandin -\n",
       "gerne har ikke været med i Landsforsøgene, men en af blandingerne har været med i de supplerende forsøg og giver forholdstal 99.\n",
       "Y derst til højre i tabel 2 er indholdet af råprotein  og rum -\n",
       "vægt angivet i gennemsnit af de seks forsøg. Proteinind -TABEL 1.\n",
       "\n",
       "------------\n",
       "\n",
       "125 BÆLGSÆD  HESTEBØNNER , SORTER\n",
       "resultater sammenholdes med resultaterne i tabel 1 og \n",
       "2, kan man sikre sig et godt overblik over sorternes ud -\n",
       "byttestabilitet og øvrige dyrkningsegenskaber.Den producerede mængde certificeret udsæd af mar -\n",
       "kært i foråret 2024 fremgår af tabel 4 sammen med for -\n",
       "delingen på de samme sorter fra 2020. Produktionen af ærteudsæd har i 2024 været cirka 20 procent lavere end \n",
       "i 2023, og kan skyldes de sene etableringsmuligheder i \n",
       "2024. Javlo anvendes næsten alene i byg/ærteblandin -\n",
       "ger eller til ærtehelsæd. Den mest dyrkede sort til mo -\n",
       "denhed er for niende år i træk Ingrid, der har udgjort 26 procent af den producerede udsæd.\n",
       "Vintermarkærter\n",
       "Der har i efteråret 2023 været lavet en plan for afprøv -\n",
       "ning af sorter af vintermarkærter i 2024 (010502424- \n",
       "vintermarkærter) på to milde lokaliteter på Lolland og \n",
       "i Østjylland. Grundet den megen nedbør blev forsøget i Østjylland ikke anlagt i efteråret 2023, og forsøget på \n",
       "Lolland blev ikke høstet i 2024 på grund af kraftige fug -\n",
       "leskader. Forsøgene gentages igen i 2024/2025 på andre \n",
       "lokaliteter.\n",
       "Hestebønner, sorter\n",
       " >MARIAN DAMSGAARD THORSTED OG  \n",
       "JON BIRGER PEDERSEN, SEGES INNOVATION\n",
       "Vårhestebønner\n",
       "Loki, der deltager i Landsforsøgene® for første gang i \n",
       "2024, giver det højeste udbytte i årets forsøg med heste-\n",
       "bønner svarende til forholdstal 107."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = collection_load.query(query_texts=[query], n_results=5)\n",
    "context = result[\"documents\"][0]\n",
    "#display(Markdown(f\"------------\\n\\n{\"\\n\\n------------\\n\\n\".join(context)}\"))\n",
    "\n",
    "formatted_text = \"\\n\\n------------\\n\\n\".join(context)\n",
    "\n",
    "# Display the formatted markdown\n",
    "display(Markdown(f\"{formatted_text}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e7a6a0",
   "metadata": {},
   "source": [
    "## Generation\n",
    "\n",
    "In this step, we will generate an answer to the question using the retrieved documents as context. We will use the OpenAI API to generate the answer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5a1f320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "You are a helpful assistant that answers questions about the course material from \"Philosophy of Computer Science (VtDat)\" using provided context.\n",
       "    Context information is below.\n",
       "    ---------------------\n",
       "    221 KUL TURTEKNIK OG JORD  AFPRØVNING  AF FREMTIDENS   BÆREDYGTIGE  DYRKNINGS SYSTEMER\n",
       "rødderne i minirhizotron-rør i Slagelse og Holstebro samt \n",
       "infiltrationsmålinger på alle lokaliteter. Disse data vil bli -\n",
       "ve offentligt i en Landbrugsinfo-artikel i starten af 2025.\n",
       "I forsøgene tilstræbes det at behandle de forskellige \n",
       "forsøgsled ud fra et mål om at optimere alle dyrknings-\n",
       "systemerne. Såtid og udsædsmængde tilpasses jordens tjenlighed i de forskellige systemer, ligesom gødsknings- \n",
       "og planteværnsstrategi tilpasses aktuelle behov.\n",
       "I 2024 er de tre storskalaforsøg videreført på fjerde år. \n",
       "Forsøgene evaluerer som nævnt dyrkningssystemerne: \n",
       "traditionel pløjning, reduceret jordbearbejdning og CA. I første forsøgsår var afgrøden hestebønner, efterfulgt af \n",
       "vinterhvede med efterafgrøde i 2022 og vårbyg i 2023. I \n",
       "efteråret 2023 blev der sået vinterraps på alle lokaliteter. På grund af dårlig fremspiring ved Slagelse, blev der om-\n",
       "sået med vinterhvede. Ligeledes blev rapsen i Birkelse \n",
       "nedvisnet i foråret 2024 på grund af dårlig plantevækst. Her blev i stedet sået havre. Omsåningen skyldes de me -get våde forhold (se foto). Den dårlige plantevækst har \n",
       "ikke været påvirket af dyrkningssystemet.\n",
       "\n",
       "Her er det forsøget ved Esbjerg d. 1. maj 2024. \n",
       "Forsøget blev kasseret.FOTO: LEIF HAGELSKJÆR, SEGES INNOVATION\n",
       "STRATEGI\n",
       "Vælg altid en vinterhvedesort eller en \n",
       "sortsblanding, der:\n",
       " >har givet et stort udbytte gennem flere års for -\n",
       "søg\n",
       " >har en god overvintringsevne\n",
       " >har en god stråstivhed, så den kan dyrkes uden \n",
       "vækstregulering\n",
       " >har en effektiv resistens over for følgende syg -\n",
       "domme (i prioriteret rækkefølge):\n",
       " – Septoria\n",
       " – gulrust\n",
       " – meldug\n",
       " – brunrust.\n",
       "En satsning på deciderede brødhvedesorter er kun aktuel, hvis der er rimelig sikkerhed for afsætning til en passende merpris.\n",
       "\n",
       "Vårhvedesorter, der har dækket over 1,0 procent af \n",
       "udsædsproduktionen i 2024. T abellen viser sorternes andel af udsædsproduktionen i procent\n",
       "Høstår 2020 2021 2022 2023 2024\n",
       "T on i alt 3.347 4.704 4.768 2.621 2.777\n",
       "Kapitol 2 25 33 52 33\n",
       "Bravens 3 14 19\n",
       "KWS Fixum 10\n",
       "KWS Sharki 3 8 9\n",
       "Sonett 5 6 5 11 8\n",
       "Dacke 2 5 3 1 7\n",
       "Thorus 21 27 28 6 4\n",
       "KWS Barolum 4\n",
       "KWS T alisker 1 2 6 4 4\n",
       "Andre sorter 70 36 19 4 2\n",
       "\n",
       "Det er bemærkelsesværdigt, at vinterbyg har klaret sig \n",
       "godt i et klimamæssigt vanskeligt år.\n",
       "Der har været anlagt ti forsøg til høst 2024, hvoraf seks \n",
       "har givet brugbare resultater. T o af de kasserede forsøg \n",
       "har været vandlidende. I et forsøg har plantebestanden været for ringe og uens, og i det sidste forsøg har der væ -\n",
       "ret en uensartet plantebestand på langs af parcellerne i halvdelen af forsøget. I tabel 2 er resultaterne af lands -\n",
       "forsøgene opdelt på tre forsøg på Øerne og tre i Jylland. \n",
       "Udbytteniveauet er 21,9 hkg pr. ha højere på Øerne end \n",
       "i Jylland, og udbyttet varierer fra 74,6 hkg pr. ha i Nord-jylland til 117,0 hkg pr. ha på Lolland i målesortsblandin -\n",
       "gen. Det er en stor variation, som typisk ses i klimamæs-sigt udfordrende år, enten med tørke eller med megen nedbør. De mest dyrkede sorter til høst 2024 har været de toradede LG Globetrotter, Bordeaux, Alaska og Or -\n",
       "cade. LG Globetrotter og Bordeaux har ikke været med \n",
       "i Landsforsøgene i 2024, mens Alaska og Orcade har gi-\n",
       "vet forholdstal 98 og 97. Desuden har sortsblandinger udgjort 18 procent af den solgte udsæd. Sortsblandin -\n",
       "gerne har ikke været med i Landsforsøgene, men en af blandingerne har været med i de supplerende forsøg og giver forholdstal 99.\n",
       "Y derst til højre i tabel 2 er indholdet af råprotein  og rum -\n",
       "vægt angivet i gennemsnit af de seks forsøg. Proteinind -TABEL 1.\n",
       "\n",
       "125 BÆLGSÆD  HESTEBØNNER , SORTER\n",
       "resultater sammenholdes med resultaterne i tabel 1 og \n",
       "2, kan man sikre sig et godt overblik over sorternes ud -\n",
       "byttestabilitet og øvrige dyrkningsegenskaber.Den producerede mængde certificeret udsæd af mar -\n",
       "kært i foråret 2024 fremgår af tabel 4 sammen med for -\n",
       "delingen på de samme sorter fra 2020. Produktionen af ærteudsæd har i 2024 været cirka 20 procent lavere end \n",
       "i 2023, og kan skyldes de sene etableringsmuligheder i \n",
       "2024. Javlo anvendes næsten alene i byg/ærteblandin -\n",
       "ger eller til ærtehelsæd. Den mest dyrkede sort til mo -\n",
       "denhed er for niende år i træk Ingrid, der har udgjort 26 procent af den producerede udsæd.\n",
       "Vintermarkærter\n",
       "Der har i efteråret 2023 været lavet en plan for afprøv -\n",
       "ning af sorter af vintermarkærter i 2024 (010502424- \n",
       "vintermarkærter) på to milde lokaliteter på Lolland og \n",
       "i Østjylland. Grundet den megen nedbør blev forsøget i Østjylland ikke anlagt i efteråret 2023, og forsøget på \n",
       "Lolland blev ikke høstet i 2024 på grund af kraftige fug -\n",
       "leskader. Forsøgene gentages igen i 2024/2025 på andre \n",
       "lokaliteter.\n",
       "Hestebønner, sorter\n",
       " >MARIAN DAMSGAARD THORSTED OG  \n",
       "JON BIRGER PEDERSEN, SEGES INNOVATION\n",
       "Vårhestebønner\n",
       "Loki, der deltager i Landsforsøgene® for første gang i \n",
       "2024, giver det højeste udbytte i årets forsøg med heste-\n",
       "bønner svarende til forholdstal 107.\n",
       "    ---------------------\n",
       "    Given the context information and not prior knowledge, answer the query. Always provide an answer in the Danish language.\n",
       "    Query: hvilken brødhvedesort til høst i 2025?\n",
       "    Answer: \n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = PromptTemplate(\"\"\"You are a helpful assistant that answers questions about the US tv show known as \"The Office\" using provided context. \n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Context: \n",
    "\n",
    "-----------------------------------\n",
    "{context}\n",
    "\n",
    "-----------------------------------\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    \"\"\"You are a helpful assistant that answers questions about the course material from \"Philosophy of Computer Science (VtDat)\" using provided context.\n",
    "    Context information is below.\n",
    "    ---------------------\n",
    "    {context}\n",
    "    ---------------------\n",
    "    Given the context information and not prior knowledge, answer the query. Always provide an answer in the Danish language.\n",
    "    Query: {query}\n",
    "    Answer: \n",
    "    \"\"\",\n",
    ")\n",
    "\n",
    "\n",
    "message = prompt.format(query=query, context=\"\\n\\n\".join(context))\n",
    "display(Markdown(f\"{message}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc83ec5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Som kunstig intelligens har jeg ingen iboende evne til at forudsige fremtidige begivenheder eller tendenser inden for landbrug eller kornsorter i 2025. Det anbefales at henvende sig til en agronom eller en anden ekspert inden for området for at få en præcis og opdateret anbefaling baseret på de seneste forskning og trends inden for branchen."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stream = openai_client.chat.completions.create(\n",
    "    messages=[{\"role\": \"user\", \"content\": query}],\n",
    "    model=\"gpt-4\",\n",
    "    stream=True)\n",
    "\n",
    "output = \"\"\n",
    "for chunk in stream:\n",
    "    if chunk.choices:  # Check if the list is not empty\n",
    "        output += chunk.choices[0].delta.content or \"\"\n",
    "    display(Markdown(f\"{output}\"), clear=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cffca2b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Konteksten indeholder ikke specifik information om, hvilken brødhvedesort der skal høstes i 2025."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stream = openai_client.chat.completions.create(\n",
    "    messages=[{\"role\": \"user\", \"content\": message}],\n",
    "    model=\"gpt-4\",\n",
    "    stream=True)\n",
    "\n",
    "output = \"\"\n",
    "for chunk in stream:\n",
    "    if chunk.choices:  # Check if the list is not empty\n",
    "        output += chunk.choices[0].delta.content or \"\"\n",
    "    display(Markdown(f\"{output}\"), clear=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cb553b",
   "metadata": {},
   "source": [
    "## SlideGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9fa2861b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Slide 1:\n",
       "Title: Analyse af Fairness i COMPAS-casen\n",
       "- Introduktion til COMPAS\n",
       "   - COMPAS-algoritmen bruges i USA's retssystem til bedømmelse af kriminelles risiko for recidivisme.\n",
       "   - Et review af denne algoritme viste en systematisk skævhed i dens fejl. \n",
       "   - Personer af farvet hud, der ikke begår ny kriminalitet, har langt højere chance for fejlagtigt at få en høj risikoscore end hvide. Omvendt gælder det for hvide for fejlagtigt at få en lav score.\n",
       "   \n",
       "Slide 2:\n",
       "Title: Gruppe Fairness og COMPAS\n",
       "- Gruppe Fairness involverer at behandle grupper af mennesker ligeligt. \n",
       "- I COMPAS-casen:\n",
       "   - Det forekommer at der er en skævhed mod farvede personer. \n",
       "   - Mulighed for gruppe-diskrimination, hvor folk med samme etniske baggrund behandles anderledes end andre grupper.\n",
       "   \n",
       "Slide 3:\n",
       "Title: Individuel Fairness og COMPAS\n",
       "- Individuel fairness handler om at behandle hver enkelt individ retfærdigt.\n",
       "- I COMPAS-casen:\n",
       "   - COMPAS-algoritmen kan potentielt behandle individuelle farvede personer uretfærdigt baseret på deres hudfarve. \n",
       "   - Potentialet for diskrimination på individuelt niveau selv hvis gruppefairness er opfyldt.\n",
       "- Afsluttende tanker: Vi skal være omhyggelige med de data, vi bruger til at træne algoritmer, og være opmærksomme på potentialerne for skjulte forudsætninger og diskriminationer."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "queries = [\n",
    "    #\"Hvad står P, L, A, C og E for i PLACE-akronymet af John Ziman\"\n",
    "    #\"Redegør for hovedtrækkene i sagen om COMPAS-algoritmen som den beskrives i Angwin et al. (2016).\"\n",
    "    #\"Hvad er verifikation og falsifikation?\"\n",
    "    #\"Redegør for hovedtrækkene i sagen om COMPAS-algoritmen som den beskrives i Angwin et al. (2016).\"\n",
    "    #\"2. COMPAS-algoritmen inddrager ikke direkte etnicitet, men den inddrager faktorer, der kan være korreleret med etnicitet (Angwin et al., 2016, 3–4). Har man som modelkonstruktør et ansvar for at undlade at inddrage faktorer, der kan korreleres med etnicitet eller andre følsomme forhold? Kan man det? Hvilke etiske overvejelser bør man have. Inddrag synspunkter fra nytte og pligtetik (kategoriske og praktiske imperativ), og Nagels synsteseetik. Hvorfor har modelkonstruktøren et etisk ansvar?\"\n",
    "    #\"Forklar begreberne group fairness og individuel fairness fra Friedler et al. (2021) og forklar hvorfor en algoritme (normalt) ikke kan udvise gruppe- og individuel fairness samtidig.\"\n",
    "    \"Analyser hvordan disse fairness-begreber (group fairness og individuel fairness) er på spil i COMPAS-casen\"\n",
    "]\n",
    "\n",
    "query = queries[-1]\n",
    "\n",
    "result = collection.query(query_texts=[query], n_results=10)\n",
    "context = result[\"documents\"][0]\n",
    "#display(Markdown(f\"------------\\n\\n{\"\\n\\n------------\\n\\n\".join(context)}\"))\n",
    "\n",
    "formatted_text = \"\\n\\n------------\\n\\n\".join(context)\n",
    "\n",
    "# Display the formatted markdown\n",
    "display(Markdown(f\"{formatted_text}\"))\n",
    "\n",
    "\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    \"\"\"You are a helpful assistant that answers questions about the course material from \"Philosophy of Computer Science (VtDat)\" using provided context.\n",
    "    Specifically, you will provide your answer such that it is generated as PowerPoint slide(s) content with 3 PowerPoint slides. If helpful, please provide the answer using bullet points.\n",
    "    Context information is below.\n",
    "    ---------------------\n",
    "    {context}\n",
    "    ---------------------\n",
    "    Given the context information and not prior knowledge, answer the query. Always provide an answer in the Danish language.\n",
    "    Query: {query}\n",
    "    Answer: \n",
    "    \"\"\",\n",
    ")\n",
    "\n",
    "message = prompt.format(query=query, context=\"\\n\\n\".join(context))\n",
    "display(Markdown(f\"{message}\"))\n",
    "\n",
    "stream = openai_client.chat.completions.create(\n",
    "    messages=[{\"role\": \"user\", \"content\": message}],\n",
    "    model=\"gpt-4\",\n",
    "    stream=True)\n",
    "\n",
    "output = \"\"\n",
    "for chunk in stream:\n",
    "    if chunk.choices:  # Check if the list is not empty\n",
    "        output += chunk.choices[0].delta.content or \"\"\n",
    "    display(Markdown(f\"{output}\"), clear=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1aaa0364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "You are a helpful assistant that answers questions about the course material from \"Philosophy of Computer Science (VtDat)\" using provided context.\n",
       "    Specifically, you will provide your answer such that it is generated as PowerPoint slide(s) content with 3 PowerPoint slides. If helpful, please provide the answer using bullet points.\n",
       "    Context information is below.\n",
       "    ---------------------\n",
       "    F or det første er de etiske argumenter\n",
       "for at bruge prædiktive algoritmer typisk utilitaristiske; den grundlæggende påstand er, at\n",
       "en algoritme som COMP AS på den eller anden måde øger den samlede nytte i samfundet og\n",
       "det er på den baggrund algoritmen skal vurderes (der kan selvfølgelig også være ikke-etiske\n",
       "begrundelser som kommercielle interesser eller andet). 620\n",
       "F or andet skal være klar over, at prædiktive algoritmer altid diskriminerer, i den forstand\n",
       "at din fremtidige adfærd estimeres på baggrund af den fortidige adfærd af den gruppe, som\n",
       "du anses for at tilhøre. Hvis man fx vil estimere hvor længe en 25 årig, ikke-rygende, køben-\n",
       "havnsk studerende lever, vil man se på, hvor længe folk i en referenceklasse af personer, der\n",
       "minder om vores 25-årige studerende i gennemsnit har levet. Det er ganske simpelt sådan, 625\n",
       "statistiske forudsigelser fungerer (i det mindste i den frekventistisk tolkning af sandsynlig-\n",
       "hed, som er mest naturlig i denne sammenhæng). Spørgsmålet er altså ikke om algoritmerne\n",
       "må diskriminere, men i højere grad hvilke faktorer, vi vil tillade, at der indgår i reference-\n",
       "klassen. Hvilke træk ved dig, kan man det etisk set forsvare at diskriminere på baggrund\n",
       "af, når du skal have en livsforsikring, ansøger om et job eller søger ind på en uddannelse? 630\n",
       "F or at svare på det spørgsmål bliver vi for det tredje nødt til at inddrage begrebet ret-\n",
       "færdighed.\n",
       "\n",
       "også et socialt gode, idet den grundlæggende autonomi og integritet, beskyttelse af privat-\n",
       "livet muliggør, ifølge Johnson er en afgørende forudsætning for at have et demokrati. Et\n",
       "demokrati kan kun fungere, hvis der er plads til at tænke anderledes og mulighed for at gøre 560\n",
       "og afprøve nye ting, som de siddende magthaverne måske ikke billiger. Uden en privatsfære,\n",
       "hvor man kan tage selvstændig stilling til og indgå med andre borgere i en kritisk dialog om\n",
       "magthavernes beslutninger kan man ikke have et demokrati. Hvis det argument er korrekt,\n",
       "er spørgsmålet om privatliv vs. sikkerhed ikke blot et spørgsmål om individuelle rettigheder\n",
       "mod almenvellets velfærd, men også et spørgsmål om forskellige former for generel velfærd. 565\n",
       "Sat på spidsen kan man sige, at valgte også står mellem den sikkerhed man kan få med\n",
       "totalitær overvågning og de fordele, et oplyst, inddragende demokratisk styre giver. Man\n",
       "kan i længden ikke have begge dele.\n",
       "10.7 Bias og algoritmisk transparens\n",
       "Brugen af algoritmer giver også en anden etisk konflikt, nemlig en konflikt mellem effek- 570\n",
       "tivitet og retfærdighed. Det har i århundrede været helt almindeligt at bruge datadrevne\n",
       "sandsynlighedsberegninger til at støtte beslutninger, der går ud på at vurdere en form for\n",
       "risiko. Hvis man fx tegner en ulykkesforsikring, vil forsikringsselskabet bruge deres viden\n",
       "om, hvor hyppigt folk, der på relevante træk ligner dig, kommer til skade, til at fastsætte\n",
       "forsikringspræmien.\n",
       "\n",
       "En\n",
       "algoritme som COMP AS, der har en større tilbøjelighed til at holde farvede i fængsel end\n",
       "ikke-farvede, vil bidrage til fastholde denne strukturelle ulighed. En datadreven algoritme\n",
       "afspejler virkeligheden, som den er, men hvis virkeligheden er racistisk, vil algoritmen også\n",
       "blive det, og hvis algoritmen bliver brugt uden forbehold, kan den bidrage til at fastholde 685\n",
       "historisk betingede diskriminerende strukturer. Der er derimod ikke noget, der tyder på, at\n",
       "mænds kortere levealder er et udtryk for strukturel diskrimination. Så med andre ord er\n",
       "det vigtigt, at se på den kontekst, en algoritme skal indgå i, når man overvejer, om den er\n",
       "retfærdig.\n",
       "Pandoras black box 690\n",
       "I en traditionel statistisk model vil man have nogenlunde styr på de variable, modellen\n",
       "inddrager. Det er dog værd at bemærke, at tingene selv med traditionelle algoritmer ik-\n",
       "ke altid er så klare; COMP AS-algoritmen inddrager således ikke direkte etnicitet som en\n",
       "variabel. Den inddrager til gengæld flere variable, der er tæt korrelerede med etnicitet, og\n",
       "dermed indgår etnicitet indirekte i algoritmen. Det gør naturligvis tingene mere besværlige, 695\n",
       "16Henrik Kragh Sørensen og Mikkel Willum Johansen (apr. 2022). „Invitation til de datalogiske fags\n",
       "videnskabsteori“ . Lærebog til brug for undervisning ved Institut for Naturfagenes Didaktik, Københavns\n",
       "Universitet. Under udarbejdelse.\n",
       "Kapitel 10, version 151 (2021-06-05).\n",
       "\n",
       "Algoritmen til forudsigelse af frafald inddrog således direkte elevernes etnicitet\n",
       "som en faktor i beregningen, men hvad nu hvis algoritmen havde en bias så den systematisk\n",
       "gav elever med en etnicitet en højre risikovurdering end elever med en anden?\n",
       "Spørgsmålet om diskrimination i algoritmer er navnligt blevet diskuteret i forbindelse 595\n",
       "med den såkaldte COMP AS-algoritme, der bruges i det amerikanske retsvæsen til vurdering\n",
       "af kriminelles tilbagefaldsrisiko. En gennemgang af algoritmen viste imidlertid en systema-\n",
       "tisk skævhed i de fejl, algoritmen lavede. Således havde farvede, der ikke senere begik ny\n",
       "kriminalitet, en langt højere chance for fejlagtigt at få en høj risikoscore end hvide, og hvide\n",
       "havde omvendt en højere chance for fejlagtigt at få en lav score end farvede (Angwin m.fl., 600\n",
       "2016 ).\n",
       "Hvis man imidlertid tager udgangspunkt i de to kategorier høj- og lav-risiko, og under-\n",
       "14Henrik Kragh Sørensen og Mikkel Willum Johansen (apr. 2022). „Invitation til de datalogiske fags\n",
       "videnskabsteori“ . Lærebog til brug for undervisning ved Institut for Naturfagenes Didaktik, Københavns\n",
       "Universitet. Under udarbejdelse.\n",
       "Kapitel 10, version 151 (2021-06-05).\n",
       "\n",
       "Algoritmisk bias er et nært forbun-\n",
       "det fænomen. Som vi så ovenfor havde Flu Trends svært ved at skel-ne in ﬂ uenza- og vintersæsonen, for-\n",
       "di de to fænomener forekom samti-digt i det oprindelige træningssæt. Det var et ret uskyldigt eksempel, men hvad nu hvis de to fænomener, der var blevet sammenblandet, var noget mere følsomt som etnicitet og kriminalitet? I navnlig det ameri-kanske retssystem støtter man sig i stigende grad til statistisk trænede algoritmer, når man skal afgøre, hvorvidt fanger skal prøveløslades. Fangerne skal udfylde et spørge-skema, og på baggrund af, hvordan det er gået fanger, der tidligere har udfyldt samme skema, kan man udregne en score for, hvor sandsyn-ligt det er, at en person vil begå ny kriminalitet. Metoden er imidlertid blevet beskyldt for konsekvent at give sorte en højre kriminalitets-score end folk af andre hudfarver. Man må ikke dømme folk alene ud fra deres hudfarve – det er racisme – men noget tyder altså på, at al-goritmen i dette tilfælde til dels har lært at gætte, om folk er sorte eller ej, præcis som Flu Trends til dels havde lært at gætte på, om vinteren nærmede sig. \n",
       "Vi risikerer naturligvis altid at \n",
       "blive mødt af fordomme, men når fordommene bygges ind i model-ler, der fremstår som neutrale og objektive, kan de være sværere at adressere. Når man bruger big data er der derfor ikke bare gode metodologiske grunde til at være opmærksom på sammenblandin-gen mellem over ﬂ adisk relaterede \n",
       "fænomener. Der kan også være gode etiske grunde til det.\n",
       "\n",
       "søger, hvor god algoritmen er til at komme med korrekte forudsigelser, er der paradoksalt\n",
       "nok ingen forskel på farvede og hvide; blandt de, der blev bedømt som højrisiko, var pro-\n",
       "centdelen af farvede, der var blevet fejlplaceret, nogenlunde lige så stor som procentdelen 605\n",
       "af hvide, og tilsvarende for de, der blev vurderet som højrisiko. Det betyder med andre\n",
       "ord, at risikoscoren er nogenlunde lige pålidelig, uanset hvilken etnicitet den person, den\n",
       "bliver lavet for, har. Y dermere har det vist sig, at man ikke kan have lighed for begge mål\n",
       "samtidig. Enten vil algoritmen som nu være lige pålidelig i sine forudsigelser uanset etnici-\n",
       "tet, men til gengæld have en systematisk skævhed i forhold til enkeltpersoners risiko for at 610\n",
       "blive fejlplaceret, eller også kan man gøre risikoen for at blive fejlplaceret lige stor uanset\n",
       "etnicitet, hvilket til gengæld betyder, at algoritmen vil være mindre pålidelig for den ene\n",
       "etniske gruppe end for den anden (for en stringent matematiske gennemgang, se Kleinberg,\n",
       "Mullainathan og Raghavan, 2017 ). Det er selvfølgelig en interessant etisk udfordring!\n",
       "Når man skal diskutere hvorvidt brugen af prædiktive algoritmer kan forsvares etisk er 615\n",
       "der er en række ting, det kan være godt at få på plads.\n",
       "\n",
       "Det er ret ukontroversielt. Det er straks mere kontroversielt, at man 575\n",
       "bl.a. i det amerikanske retsvæsen siden starten af den 20. århundrede har brugt lignende\n",
       "beregninger til at vurdere kriminelles risiko for at begå ny kriminalitet – og at den type\n",
       "beregninger er blevet brugt i vurderingen strafudmåling, prøveløsladelser mv. (Carlson, A.\n",
       "(2017). The Need for T ransparency in the Age of Predictive Sentencing Algorithms. Iowa\n",
       "Law Review, 103(1), 303–329.). I de sidste årtier har lettere adgang til store datamængder 580\n",
       "og fremkomsten af diverse machine learning teknikker gjort det lettere at udvikle den type\n",
       "systemer og diverse former for prædiktive algoritmer bruges i dag på en lang række områder\n",
       "fra reklamer til sortering af jobansøgninger.\n",
       "Det er dog ikke helt uproblematisk at bruge prædiktive algoritmer. Som vi så tidligere, er\n",
       "der en række epistemiske problemer forbundet med machine learning. Der er typisk en meget 585\n",
       "direkte sammenhæng mellem epistemiske og etiske overvejelser; hvis de etiske overvejelser\n",
       "inddrager utilititaristiske komponenter er det i høj grad væsentligt at forstå, hvor godt en\n",
       "given algoritme i praksis virker. Ville den etiske vurdering af algoritmen til forudsigelse af\n",
       "frafald i gymnasiet fx falde anderledes ud, hvis systemet kun havde en træfsikkerhed på\n",
       "67%? Der er imidlertid også et anden og vanskeligere etisk aspekt specielt hvis man bruger 590\n",
       "algoritmiske forudsigelser til at træffe afgørelser, der har betydning for enkeltindividers\n",
       "muligheder.\n",
       "\n",
       "at man på den måde kan komme til at bruge variable, man ikke direkte har indbygget i sin\n",
       "algoritme.\n",
       "Det problem bliver imidlertid kraftigt forstærket, hvis man træner en algoritme med\n",
       "machine learning. Her har vi styr på de data, algoritmen er trænet med, og vi kan opstille\n",
       "forskellige mål for, hvor godt den virker, men resten er en black box; vi aner reelt ikke 700\n",
       "hvorfor den virker, og som vi berørte ovenfor, kan machine learning algoritmer med lethed\n",
       "diskriminere langs variable, der er af en helt anden type den de data, vi har trænet algo-\n",
       "ritmen med. Hvis vi vil sikre, at de algoritmer, vi udvikler, ikke diskriminerer på en etisk\n",
       "kritisabel måde, bliver vi nødt til at gøre dem transparente. Det er imidlertid ikke altid let,\n",
       "at gøre en blackbox transparent! 705\n",
       "10.8 Systemisk etik\n",
       "Efter at have set på de normative teorier vil vi nu vende tilbage til den deskriptive etik og\n",
       "beskrive et interessant og i høj grad overset aspekt af etikken, nemlig det tilsyneladende\n",
       "empiriske faktum, at vores etiske beslutninger kan påvirkes af selv små ændringer i vores\n",
       "miljø. Som et enkelt eksempel testede John M. Darley (1938–2018) og Daniel Batson 710\n",
       "teologistuderende i et eksperimentelt paradigme, hvor en forsøgsperson (typisk en stude-\n",
       "rende) bliver bedt om at forberede et kort oplæg om den barmhjertige samaritaner, som\n",
       "er en lignelse fra Det Nye T estamente, der i korte træk går ud på, at man ubetinget skal\n",
       "hjælpe andre i nød, også selv om det er en vildt fremmet af et andet folk (Darley og Bat-\n",
       "son, 1973 ).\n",
       "\n",
       "Og hvad gør man så? Er\n",
       "det mest retfærdige at kønsdiskriminere i dette tilfælde (og lade de fornuftige mænd betale 665\n",
       "prisen) eller er det mest retfærdigt at undlade at kønsdiskriminere (og lade kvinderne betale\n",
       "prisen)?\n",
       "Det bringer os tilbage til COMP AS-algoritmen. I den population, hvor algoritmen er\n",
       "blevet testet, har farvede fanger reelt en større risiko for at begå ny kriminalitet. Når\n",
       "algoritmen diskriminerer på baggrund af etnicitet er det derfor blot et udtryk for, at den 670\n",
       "har identificeret en informationsbærende dimension i datasættet. Og lige som ovenfor vil vi\n",
       "have valget imellem at forhindre algoritmen i at bruge informationen, hvorved den vil blive\n",
       "mindre effektiv i den forstand at dens overordnede fejlrate vil stige, eller at tillade den at\n",
       "bruge informationen, hvorved den vil diskriminere enkeltindivider, således at farvede, der\n",
       "ikke vil begå ny kriminalitet har en meget større risiko for at få en høj kriminalitetsscore 675\n",
       "end ikke-farvede. Hvilket af de to scenarier forekommer dig mest retfærdigt, når du står\n",
       "bag uvidenhedens slør?\n",
       "Der er dog også væsentlige forskelle på de to cases. Specielt kan man argumentere for, at\n",
       "den gennensnitligt høje kriminalitetsrate blandt farvede til dels skyldes strukturelle forhold\n",
       "i det amerikanske samfund; pga. en generel diskrimination mod farvede har de sværere ved 680\n",
       "at få uddannelser og job end ikke-farvede, og derfor vil de hyppigere ende i kriminalitet.\n",
       "\n",
       "Begrebet retfærdighed befinder sig et sted imellem etik og politisk filosofi, idet\n",
       "det angår mere generelle egenskaber samfund, som fordeling af goder, adgang til politisk\n",
       "magt og det juridiske straffesystem. Præcis som det er tilfældet for etik findes der mange\n",
       "forskellige retninger indenfor politisk filosofi, og mange forskellige ideer om, hvad retfærdig- 635\n",
       "hed er. Det vil vi på ingen måde gå i dybden med her. Vi vil nøjes med at præsentere en\n",
       "enkelt og meget operationel forestilling om retfærdighed, til dels med udgangspunkt i den\n",
       "amerikanske filosof John Ra wls (1921–2002). Ra wls hævder (Rawls, 1972 ), at hvis sam-\n",
       "fundet skal være retfærdigt, skal vi tage alle grundlæggende beslutninger om det indretning\n",
       "og institutioner, mens vi befinder os bag et uvidenhedens slør , der skjuler, hvilken position 640\n",
       "vi selv vil få i samfundet. Så man skal altså forestille sig, at man ikke ved, hvilket køn man\n",
       "har, at man ikke ved, om man er rig eller fattig, at man ikke kender sin etnicitet mv., og\n",
       "ud fra den position kan man beslutte, hvordan samfundet skal indrettes. I dette tilfælde:\n",
       "Hvilke former for diskrimination vil vi tillade i prædiktive algoritmer? Det er let at forestille\n",
       "sig (men det kan selvfølgelig diskuteres) at man i den situation vil vælge et samfund der 645\n",
       "er uden kønsdiskrimination og ude diskrimination mode fx seksuelle og etniske minoriteter.\n",
       "Så simpelt er det.\n",
       "Og så alligevel ikke, for der kan være principielt forskellige former for diskrimination.\n",
       "    ---------------------\n",
       "    Given the context information and not prior knowledge, answer the query. Always provide an answer in the Danish language.\n",
       "    Query: Forklar begreberne group fairness og individuel fairness fra Friedler et al. (2021) og forklar hvorfor en algoritme (normalt) ikke kan udvise gruppe- og individuel fairness samtidig.\n",
       "    Answer: \n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"{message}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1fad80",
   "metadata": {},
   "source": [
    "## Normal example using LlamaIndex\n",
    "\n",
    "In this example, we will use LlamaIndex to abstract the indexing and retrieval steps. This shows how easily the same pipeline can be implemented using LlamaIndex.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ae94f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#%pip install llama-index-embeddings-azure-openai\n",
    "#%pip install llama-index-llms-azure-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "356930ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb import Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "\n",
    "from llama_index.llms.azure_openai import AzureOpenAI\n",
    "from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding\n",
    "\n",
    "# ChromaDB Vector Store\n",
    "chroma_client = chromadb.PersistentClient(\n",
    "    path=\"./data/baseline-rag-pdf-docs/chromadb\", settings=Settings(allow_reset=True))\n",
    "chroma_client.reset()\n",
    "collection = chroma_client.get_or_create_collection(\n",
    "    name=\"VtDat\", metadata={\"hnsw:space\": \"cosine\"})\n",
    "vector_store = ChromaVectorStore(chroma_collection=collection)\n",
    "\n",
    "\n",
    "llm = AzureOpenAI(\n",
    "    model=\"gpt-4\",\n",
    "    deployment_name=\"gpt-4\",\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),  \n",
    "    api_version=os.getenv(\"OPENAI_API_VERSION\"), # https://learn.microsoft.com/en-us/azure/ai-services/openai/reference?WT.mc_id=AZ-MVP-5004796\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    ")\n",
    "\n",
    "# You need to deploy your own embedding model as well as your own chat completion model\n",
    "embed_model = AzureOpenAIEmbedding(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    deployment_name=\"text-embedding-ada-002\",\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),  \n",
    "    api_version=os.getenv(\"OPENAI_API_VERSION\"), # https://learn.microsoft.com/en-us/azure/ai-services/openai/reference?WT.mc_id=AZ-MVP-5004796\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    ")\n",
    "\n",
    "# Define the ingestion pipeline to add documents to vector store\n",
    "pipeline = IngestionPipeline(\n",
    "    transformations=[\n",
    "        SentenceSplitter(chunk_size=512, chunk_overlap=20),\n",
    "        embed_model,\n",
    "    ],\n",
    "    vector_store=vector_store,\n",
    ")\n",
    "\n",
    "# Create index with the vector store and using the embedding model\n",
    "index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store=vector_store, embed_model=embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58348922",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 17 0 (offset 0)\n",
      "Ignoring wrong pointing object 65 0 (offset 0)\n",
      "Ignoring wrong pointing object 96 0 (offset 0)\n",
      "Ignoring wrong pointing object 12 0 (offset 0)\n",
      "Ignoring wrong pointing object 23 0 (offset 0)\n",
      "Ignoring wrong pointing object 32 0 (offset 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing complete\n"
     ]
    }
   ],
   "source": [
    "# Fetch documents\n",
    "documents = SimpleDirectoryReader('./data/docs').load_data()\n",
    "\n",
    "# Run pipeline\n",
    "pipeline.run(documents=documents)\n",
    "\n",
    "print(\"Indexing complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6751921c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever at 0x21685826610>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69e3626c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     c:\\Users\\jach\\AppData\\Local\\miniconda3\\envs\\advanced-\n",
      "[nltk_data]     rag-env\\Lib\\site-\n",
      "[nltk_data]     packages\\llama_index\\core\\_static/nltk_cache...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-14 22:15:45.102 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run c:\\Users\\jach\\AppData\\Local\\miniconda3\\envs\\advanced-rag-env\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "import hmac\n",
    "from openai import AzureOpenAI\n",
    "from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding\n",
    "import streamlit as st\n",
    "import chromadb\n",
    "import chromadb.utils.embedding_functions as embedding_functions\n",
    "\n",
    "\n",
    "client = AzureOpenAI(api_key=st.secrets[\"OPENAI_API_KEY\"], \n",
    "                api_version=\"2024-05-01-preview\", \n",
    "                azure_endpoint=st.secrets[\"AZURE_OPENAI_ENDPOINT\"])\n",
    "\n",
    "openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "    api_key=st.secrets[\"EMBEDDING_OPENAI_API_KEY\"],\n",
    "    model_name=st.secrets[\"EMBEDDING_OPENAI_DEPLOYMENT_NAME\"],\n",
    "    api_type=\"azure\",\n",
    "    api_version=st.secrets[\"EMBEDDING_OPENAI_API_VERSION\"]\n",
    ")\n",
    "\n",
    "#embed_model = AzureOpenAIEmbedding(\n",
    "#    model=st.secrets[\"EMBEDDING_OPENAI_DEPLOYMENT_NAME\"],\n",
    "#    deployment_name=st.secrets[\"EMBEDDING_OPENAI_DEPLOYMENT_NAME\"],\n",
    "#    api_key=st.secrets[\"EMBEDDING_OPENAI_API_KEY\"],  \n",
    "#    api_version=st.secrets[\"EMBEDDING_OPENAI_API_VERSION\"], # https://learn.microsoft.com/en-us/azure/ai-services/openai/reference?WT.mc_id=AZ-MVP-5004796\n",
    "#    azure_endpoint=st.secrets[\"EMBEDDING_AZURE_OPENAI_ENDPOINT\"]\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acab3916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-05-01-preview'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.secrets[\"EMBEDDING_OPENAI_API_VERSION\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "103a5929",
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mopenai_ef\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhello\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jach\\AppData\\Local\\miniconda3\\envs\\advanced-rag-env\\Lib\\site-packages\\chromadb\\api\\types.py:193\u001b[0m, in \u001b[0;36mEmbeddingFunction.__init_subclass__.<locals>.__call__\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m: EmbeddingFunction[D], \u001b[38;5;28minput\u001b[39m: D) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Embeddings:\n\u001b[1;32m--> 193\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m validate_embeddings(maybe_cast_one_to_many_embedding(result))\n",
      "File \u001b[1;32mc:\\Users\\jach\\AppData\\Local\\miniconda3\\envs\\advanced-rag-env\\Lib\\site-packages\\chromadb\\utils\\embedding_functions.py:201\u001b[0m, in \u001b[0;36mOpenAIEmbeddingFunction.__call__\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# Call the OpenAI Embedding API\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_v1:\n\u001b[1;32m--> 201\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_deployment_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model_name\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdata\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;66;03m# Sort resulting embeddings by index\u001b[39;00m\n\u001b[0;32m    206\u001b[0m     sorted_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(embeddings, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m e: e\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\jach\\AppData\\Local\\miniconda3\\envs\\advanced-rag-env\\Lib\\site-packages\\openai\\resources\\embeddings.py:114\u001b[0m, in \u001b[0;36mEmbeddings.create\u001b[1;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    108\u001b[0m         embedding\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[0;32m    109\u001b[0m             base64\u001b[38;5;241m.\u001b[39mb64decode(data), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    110\u001b[0m         )\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/embeddings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmbeddingCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCreateEmbeddingResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jach\\AppData\\Local\\miniconda3\\envs\\advanced-rag-env\\Lib\\site-packages\\openai\\_base_client.py:1240\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1226\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1227\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1228\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1235\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1236\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1237\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1238\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1239\u001b[0m     )\n\u001b[1;32m-> 1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\jach\\AppData\\Local\\miniconda3\\envs\\advanced-rag-env\\Lib\\site-packages\\openai\\_base_client.py:921\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    912\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    913\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    914\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    919\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    920\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m--> 921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jach\\AppData\\Local\\miniconda3\\envs\\advanced-rag-env\\Lib\\site-packages\\openai\\_base_client.py:1020\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1017\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1019\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1020\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1023\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1024\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1027\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1028\u001b[0m )\n",
      "\u001b[1;31mAuthenticationError\u001b[0m: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}"
     ]
    }
   ],
   "source": [
    "openai_ef(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab650f35",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can't instantiate abstract class OpenAI with abstract method _prepare_chat_with_tools",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 43\u001b[0m\n\u001b[0;32m     36\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mcomplete(\n\u001b[0;32m     37\u001b[0m             qa_prompt\u001b[38;5;241m.\u001b[39mformat(context_str\u001b[38;5;241m=\u001b[39mcontext_str, query_str\u001b[38;5;241m=\u001b[39mquery_str)\n\u001b[0;32m     38\u001b[0m         )\n\u001b[0;32m     40\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(response) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mKontekst:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m context_str\n\u001b[1;32m---> 43\u001b[0m synthesizer \u001b[38;5;241m=\u001b[39m \u001b[43mget_response_synthesizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompact\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m query_engine \u001b[38;5;241m=\u001b[39m RAGQueryEngine(\n\u001b[0;32m     45\u001b[0m     retriever\u001b[38;5;241m=\u001b[39mindex\u001b[38;5;241m.\u001b[39mas_retriever(),\n\u001b[0;32m     46\u001b[0m     response_synthesizer\u001b[38;5;241m=\u001b[39msynthesizer,\n\u001b[0;32m     47\u001b[0m     llm\u001b[38;5;241m=\u001b[39mllm,\n\u001b[0;32m     48\u001b[0m     qa_prompt\u001b[38;5;241m=\u001b[39mqa_prompt,\n\u001b[0;32m     49\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\jach\\AppData\\Local\\miniconda3\\envs\\advanced-rag-env\\Lib\\site-packages\\llama_index\\core\\response_synthesizers\\factory.py:65\u001b[0m, in \u001b[0;36mget_response_synthesizer\u001b[1;34m(llm, prompt_helper, service_context, text_qa_template, refine_template, summary_template, simple_template, response_mode, callback_manager, use_async, streaming, structured_answer_filtering, output_cls, program_factory, verbose)\u001b[0m\n\u001b[0;32m     60\u001b[0m summary_template \u001b[38;5;241m=\u001b[39m summary_template \u001b[38;5;129;01mor\u001b[39;00m DEFAULT_TREE_SUMMARIZE_PROMPT_SEL\n\u001b[0;32m     62\u001b[0m callback_manager \u001b[38;5;241m=\u001b[39m callback_manager \u001b[38;5;129;01mor\u001b[39;00m callback_manager_from_settings_or_context(\n\u001b[0;32m     63\u001b[0m     Settings, service_context\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m llm \u001b[38;5;241m=\u001b[39m llm \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mllm_from_settings_or_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSettings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_context\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m service_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     68\u001b[0m     prompt_helper \u001b[38;5;241m=\u001b[39m service_context\u001b[38;5;241m.\u001b[39mprompt_helper\n",
      "File \u001b[1;32mc:\\Users\\jach\\AppData\\Local\\miniconda3\\envs\\advanced-rag-env\\Lib\\site-packages\\llama_index\\core\\settings.py:264\u001b[0m, in \u001b[0;36mllm_from_settings_or_context\u001b[1;34m(settings, context)\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m context\u001b[38;5;241m.\u001b[39mllm\n\u001b[1;32m--> 264\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msettings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jach\\AppData\\Local\\miniconda3\\envs\\advanced-rag-env\\Lib\\site-packages\\llama_index\\core\\settings.py:39\u001b[0m, in \u001b[0;36m_Settings.llm\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get the LLM.\"\"\"\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_llm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 39\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_llm \u001b[38;5;241m=\u001b[39m \u001b[43mresolve_llm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdefault\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_llm\u001b[38;5;241m.\u001b[39mcallback_manager \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback_manager\n",
      "File \u001b[1;32mc:\\Users\\jach\\AppData\\Local\\miniconda3\\envs\\advanced-rag-env\\Lib\\site-packages\\llama_index\\core\\llms\\utils.py:41\u001b[0m, in \u001b[0;36mresolve_llm\u001b[1;34m(llm, callback_manager)\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI  \u001b[38;5;66;03m# pants: no-infer-dep\u001b[39;00m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     38\u001b[0m         validate_openai_api_key,\n\u001b[0;32m     39\u001b[0m     )  \u001b[38;5;66;03m# pants: no-infer-dep\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m     llm \u001b[38;5;241m=\u001b[39m \u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m     validate_openai_api_key(llm\u001b[38;5;241m.\u001b[39mapi_key)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: Can't instantiate abstract class OpenAI with abstract method _prepare_chat_with_tools"
     ]
    }
   ],
   "source": [
    "from llama_index.core import PromptTemplate\n",
    "from llama_index.core.query_engine import CustomQueryEngine\n",
    "from llama_index.core.retrievers import BaseRetriever\n",
    "from llama_index.core import get_response_synthesizer\n",
    "from llama_index.core.response_synthesizers import BaseSynthesizer\n",
    "\n",
    "    \n",
    "qa_prompt = PromptTemplate(\n",
    "    \"\"\"You are a helpful assistant that answers questions about the content of documents and provides detailed expert advice. \n",
    "    You must provide your answer in the Danish language.\n",
    "    If the answer contains multiple steps or points, provide the answer in a bullet format.\n",
    "    Below the answer, the source of the answer should be provided including file name and page number.\n",
    "    ---------------------\n",
    "    {context_str}\n",
    "    ---------------------\n",
    "    Given the context information and not prior knowledge, answer the query.\n",
    "    Query: {query_str}\n",
    "    Answer: \n",
    "    \"\"\",\n",
    ")\n",
    "\n",
    "\n",
    "class RAGQueryEngine(CustomQueryEngine):\n",
    "    \"\"\"RAG String Query Engine.\"\"\"\n",
    "\n",
    "    retriever: BaseRetriever\n",
    "    response_synthesizer: BaseSynthesizer\n",
    "    llm: OpenAI\n",
    "    qa_prompt: PromptTemplate\n",
    "\n",
    "    def custom_query(self, query_str: str):\n",
    "        nodes = self.retriever.retrieve(query_str)\n",
    "        context_str = \"\\n\\n\".join([n.node.get_content(metadata_mode=\"all\") for n in nodes])\n",
    "        #context = qa_prompt.format(\n",
    "        #    context_str=context_str, query_str=query_str)\n",
    "        response = self.llm.complete(\n",
    "            qa_prompt.format(context_str=context_str, query_str=query_str)\n",
    "        )\n",
    "                    \n",
    "        return str(response) + \"\\n\\n-------------------------\\n\\nKontekst:\\n\\n\" + context_str\n",
    "\n",
    "\n",
    "synthesizer = get_response_synthesizer(response_mode=\"compact\")\n",
    "query_engine = RAGQueryEngine(\n",
    "    retriever=index.as_retriever(),\n",
    "    response_synthesizer=synthesizer,\n",
    "    llm=llm,\n",
    "    qa_prompt=qa_prompt,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afa9720",
   "metadata": {},
   "source": [
    "#### Create base QueryEngine from LlamaIndex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "79604a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine(llm=llm, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f4a4ed",
   "metadata": {},
   "source": [
    "#### Or alternatively, create a CustomQueryEngine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9f60384",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can't instantiate abstract class MyRetriever with abstract method _retrieve",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 53\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(response)\n\u001b[0;32m     51\u001b[0m synthesizer \u001b[38;5;241m=\u001b[39m get_response_synthesizer(response_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompact\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     52\u001b[0m query_engine \u001b[38;5;241m=\u001b[39m RAGQueryEngine(\n\u001b[1;32m---> 53\u001b[0m     retriever\u001b[38;5;241m=\u001b[39m \u001b[43mMyRetriever\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_retriever\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m,\u001b[38;5;66;03m#index.as_retriever(),\u001b[39;00m\n\u001b[0;32m     54\u001b[0m     response_synthesizer\u001b[38;5;241m=\u001b[39msynthesizer,\n\u001b[0;32m     55\u001b[0m     llm\u001b[38;5;241m=\u001b[39mllm,\n\u001b[0;32m     56\u001b[0m     qa_prompt\u001b[38;5;241m=\u001b[39mqa_prompt,\n\u001b[0;32m     57\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: Can't instantiate abstract class MyRetriever with abstract method _retrieve"
     ]
    }
   ],
   "source": [
    "from llama_index.core import PromptTemplate\n",
    "from llama_index.core.query_engine import CustomQueryEngine\n",
    "from llama_index.core.retrievers import BaseRetriever\n",
    "from llama_index.core import get_response_synthesizer\n",
    "from llama_index.core.response_synthesizers import BaseSynthesizer\n",
    "\n",
    "\n",
    "class MyRetriever(BaseRetriever):\n",
    "    def retrieve(self, query_str: str, max_documents: int = 10):\n",
    "        # Get all documents relevant to the query\n",
    "        all_documents = super().retrieve(query_str)\n",
    "\n",
    "        # Return only the first `max_documents` documents\n",
    "        return all_documents[:max_documents]\n",
    "\n",
    "\n",
    "qa_prompt = PromptTemplate(\n",
    "    \"\"\"You are a helpful assistant that answers questions about the course material from \"Philosophy of Computer Science (VtDat)\" using provided context.\n",
    "    Context information is below.\n",
    "    ---------------------\n",
    "    {context_str}\n",
    "    ---------------------\n",
    "    Given the context information and not prior knowledge, answer the query. Always provide an answer in the Danish language.\n",
    "    Query: {query_str}\n",
    "    Answer: \n",
    "    \"\"\",\n",
    ")\n",
    "\n",
    "\n",
    "class RAGQueryEngine(CustomQueryEngine):\n",
    "    \"\"\"RAG String Query Engine.\"\"\"\n",
    "\n",
    "    retriever: MyRetriever #BaseRetriever\n",
    "    response_synthesizer: BaseSynthesizer\n",
    "    llm: OpenAI\n",
    "    qa_prompt: PromptTemplate\n",
    "\n",
    "    def custom_query(self, query_str: str):\n",
    "        #nodes = self.retriever.retrieve(query_str)#\n",
    "        nodes = self.retriever.retrieve(query_str, max_documents=5)\n",
    "        context_str = \"\\n\\n\".join([n.node.get_content() for n in nodes])\n",
    "        print(\"Prompt:\\n\\n\", qa_prompt.format(\n",
    "            context_str=context_str, query_str=query_str))\n",
    "        response = self.llm.complete(\n",
    "            qa_prompt.format(context_str=context_str, query_str=query_str)\n",
    "        )\n",
    "\n",
    "        return str(response)\n",
    "\n",
    "\n",
    "synthesizer = get_response_synthesizer(response_mode=\"compact\")\n",
    "query_engine = RAGQueryEngine(\n",
    "    retriever = index.as_retriever(),\n",
    "    response_synthesizer=synthesizer,\n",
    "    llm=llm,\n",
    "    qa_prompt=qa_prompt,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ab9d8ae2",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidCollectionException",
     "evalue": "Collection e3406e00-da5e-41a3-b052-410e1e72d3a9 does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidCollectionException\u001b[0m                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 15\u001b[0m\n\u001b[0;32m      1\u001b[0m queries \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m#\"What are some of the made-up characters impersonated by Michael Scott? Give a oneliner description for each character.\",\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m#\"Who is the character that is known for his 'That's what she said' jokes in The Office?\",\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHvad dækker P, L, A, C og E over i PLACE-akronymet af John Ziman over?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     11\u001b[0m ]\n\u001b[0;32m     13\u001b[0m query \u001b[38;5;241m=\u001b[39m queries[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m---> 15\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mquery_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m display(Markdown(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\jach\\AppData\\Local\\miniconda3\\envs\\advanced-rag-env\\Lib\\site-packages\\llama_index\\core\\query_engine\\custom.py:45\u001b[0m, in \u001b[0;36mCustomQueryEngine.query\u001b[1;34m(self, str_or_query_bundle)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     44\u001b[0m     query_str \u001b[38;5;241m=\u001b[39m str_or_query_bundle\n\u001b[1;32m---> 45\u001b[0m raw_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcustom_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m     47\u001b[0m     Response(raw_response)\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(raw_response, \u001b[38;5;28mstr\u001b[39m)\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m raw_response\n\u001b[0;32m     50\u001b[0m )\n",
      "Cell \u001b[1;32mIn[14], line 29\u001b[0m, in \u001b[0;36mRAGQueryEngine.custom_query\u001b[1;34m(self, query_str)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcustom_query\u001b[39m(\u001b[38;5;28mself\u001b[39m, query_str: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m---> 29\u001b[0m     nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m     context_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([n\u001b[38;5;241m.\u001b[39mnode\u001b[38;5;241m.\u001b[39mget_content() \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m nodes])\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrompt:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, qa_prompt\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m     32\u001b[0m         context_str\u001b[38;5;241m=\u001b[39mcontext_str, query_str\u001b[38;5;241m=\u001b[39mquery_str))\n",
      "File \u001b[1;32mc:\\Users\\jach\\AppData\\Local\\miniconda3\\envs\\advanced-rag-env\\Lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:274\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[0;32m    271\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_, bound_args\u001b[38;5;241m=\u001b[39mbound_args, instance\u001b[38;5;241m=\u001b[39minstance, parent_id\u001b[38;5;241m=\u001b[39mparent_id\n\u001b[0;32m    272\u001b[0m )\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 274\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[1;32mc:\\Users\\jach\\AppData\\Local\\miniconda3\\envs\\advanced-rag-env\\Lib\\site-packages\\llama_index\\core\\base\\base_retriever.py:244\u001b[0m, in \u001b[0;36mBaseRetriever.retrieve\u001b[1;34m(self, str_or_query_bundle)\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mas_trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mevent(\n\u001b[0;32m    241\u001b[0m         CBEventType\u001b[38;5;241m.\u001b[39mRETRIEVE,\n\u001b[0;32m    242\u001b[0m         payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mQUERY_STR: query_bundle\u001b[38;5;241m.\u001b[39mquery_str},\n\u001b[0;32m    243\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m retrieve_event:\n\u001b[1;32m--> 244\u001b[0m         nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_bundle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    245\u001b[0m         nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_recursive_retrieval(query_bundle, nodes)\n\u001b[0;32m    246\u001b[0m         retrieve_event\u001b[38;5;241m.\u001b[39mon_end(\n\u001b[0;32m    247\u001b[0m             payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mNODES: nodes},\n\u001b[0;32m    248\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\jach\\AppData\\Local\\miniconda3\\envs\\advanced-rag-env\\Lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:274\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[0;32m    271\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_, bound_args\u001b[38;5;241m=\u001b[39mbound_args, instance\u001b[38;5;241m=\u001b[39minstance, parent_id\u001b[38;5;241m=\u001b[39mparent_id\n\u001b[0;32m    272\u001b[0m )\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 274\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[1;32mc:\\Users\\jach\\AppData\\Local\\miniconda3\\envs\\advanced-rag-env\\Lib\\site-packages\\llama_index\\core\\indices\\vector_store\\retrievers\\retriever.py:101\u001b[0m, in \u001b[0;36mVectorIndexRetriever._retrieve\u001b[1;34m(self, query_bundle)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m query_bundle\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(query_bundle\u001b[38;5;241m.\u001b[39membedding_strs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     96\u001b[0m         query_bundle\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     97\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embed_model\u001b[38;5;241m.\u001b[39mget_agg_embedding_from_queries(\n\u001b[0;32m     98\u001b[0m                 query_bundle\u001b[38;5;241m.\u001b[39membedding_strs\n\u001b[0;32m     99\u001b[0m             )\n\u001b[0;32m    100\u001b[0m         )\n\u001b[1;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_nodes_with_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_bundle\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jach\\AppData\\Local\\miniconda3\\envs\\advanced-rag-env\\Lib\\site-packages\\llama_index\\core\\indices\\vector_store\\retrievers\\retriever.py:177\u001b[0m, in \u001b[0;36mVectorIndexRetriever._get_nodes_with_embeddings\u001b[1;34m(self, query_bundle_with_embeddings)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_nodes_with_embeddings\u001b[39m(\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28mself\u001b[39m, query_bundle_with_embeddings: QueryBundle\n\u001b[0;32m    175\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[NodeWithScore]:\n\u001b[0;32m    176\u001b[0m     query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_vector_store_query(query_bundle_with_embeddings)\n\u001b[1;32m--> 177\u001b[0m     query_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_vector_store\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_node_list_from_query_result(query_result)\n",
      "File \u001b[1;32mc:\\Users\\jach\\AppData\\Local\\miniconda3\\envs\\advanced-rag-env\\Lib\\site-packages\\llama_index\\vector_stores\\chroma\\base.py:312\u001b[0m, in \u001b[0;36mChromaVectorStore.query\u001b[1;34m(self, query, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m query\u001b[38;5;241m.\u001b[39mquery_embedding:\n\u001b[0;32m    310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get(limit\u001b[38;5;241m=\u001b[39mquery\u001b[38;5;241m.\u001b[39msimilarity_top_k, where\u001b[38;5;241m=\u001b[39mwhere, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 312\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_embedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_top_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jach\\AppData\\Local\\miniconda3\\envs\\advanced-rag-env\\Lib\\site-packages\\llama_index\\vector_stores\\chroma\\base.py:322\u001b[0m, in \u001b[0;36mChromaVectorStore._query\u001b[1;34m(self, query_embeddings, n_results, where, **kwargs)\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_query\u001b[39m(\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m, query_embeddings: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat\u001b[39m\u001b[38;5;124m\"\u001b[39m], n_results: \u001b[38;5;28mint\u001b[39m, where: \u001b[38;5;28mdict\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    321\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VectorStoreQueryResult:\n\u001b[1;32m--> 322\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_collection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    327\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    329\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m> Top \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdocuments\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m nodes:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    330\u001b[0m     nodes \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\jach\\AppData\\Local\\miniconda3\\envs\\advanced-rag-env\\Lib\\site-packages\\chromadb\\api\\models\\Collection.py:345\u001b[0m, in \u001b[0;36mCollection.query\u001b[1;34m(self, query_embeddings, query_texts, query_images, query_uris, n_results, where, where_document, include)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m include \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muris\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m include:\n\u001b[0;32m    344\u001b[0m     valid_include\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muris\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 345\u001b[0m query_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_query_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_n_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_where\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwhere_document\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_where_document\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    355\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m include\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_loader \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    357\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m query_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muris\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    358\u001b[0m ):\n\u001b[0;32m    359\u001b[0m     query_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    360\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_loader(uris) \u001b[38;5;28;01mfor\u001b[39;00m uris \u001b[38;5;129;01min\u001b[39;00m query_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muris\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    361\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\jach\\AppData\\Local\\miniconda3\\envs\\advanced-rag-env\\Lib\\site-packages\\chromadb\\telemetry\\opentelemetry\\__init__.py:143\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity \u001b[38;5;241m<\u001b[39m granularity:\n\u001b[1;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jach\\AppData\\Local\\miniconda3\\envs\\advanced-rag-env\\Lib\\site-packages\\chromadb\\rate_limiting\\__init__.py:45\u001b[0m, in \u001b[0;36mrate_limit.<locals>.decorator.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Dict[Any, Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# If not rate limiting provider is present, just run and return the function.\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_system\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39mchroma_rate_limiting_provider_impl \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 45\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m subject \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[0;32m     48\u001b[0m         subject_value \u001b[38;5;241m=\u001b[39m kwargs[subject]\n",
      "File \u001b[1;32mc:\\Users\\jach\\AppData\\Local\\miniconda3\\envs\\advanced-rag-env\\Lib\\site-packages\\chromadb\\api\\segment.py:683\u001b[0m, in \u001b[0;36mSegmentAPI._query\u001b[1;34m(self, collection_id, query_embeddings, n_results, where, where_document, include)\u001b[0m\n\u001b[0;32m    675\u001b[0m where_document \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    676\u001b[0m     validate_where_document(where_document)\n\u001b[0;32m    677\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m where_document \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(where_document) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    678\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m where_document\n\u001b[0;32m    679\u001b[0m )\n\u001b[0;32m    681\u001b[0m allowed_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 683\u001b[0m coll \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcollection_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    684\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m embedding \u001b[38;5;129;01min\u001b[39;00m query_embeddings:\n\u001b[0;32m    685\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_dimension(coll, \u001b[38;5;28mlen\u001b[39m(embedding), update\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\jach\\AppData\\Local\\miniconda3\\envs\\advanced-rag-env\\Lib\\site-packages\\chromadb\\telemetry\\opentelemetry\\__init__.py:143\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity \u001b[38;5;241m<\u001b[39m granularity:\n\u001b[1;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jach\\AppData\\Local\\miniconda3\\envs\\advanced-rag-env\\Lib\\site-packages\\chromadb\\api\\segment.py:837\u001b[0m, in \u001b[0;36mSegmentAPI._get_collection\u001b[1;34m(self, collection_id)\u001b[0m\n\u001b[0;32m    835\u001b[0m     collections \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sysdb\u001b[38;5;241m.\u001b[39mget_collections(\u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39mcollection_id)\n\u001b[0;32m    836\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m collections:\n\u001b[1;32m--> 837\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidCollectionException(\n\u001b[0;32m    838\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCollection \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcollection_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    839\u001b[0m         )\n\u001b[0;32m    840\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_collection_cache[collection_id] \u001b[38;5;241m=\u001b[39m collections[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    841\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_collection_cache[collection_id]\n",
      "\u001b[1;31mInvalidCollectionException\u001b[0m: Collection e3406e00-da5e-41a3-b052-410e1e72d3a9 does not exist."
     ]
    }
   ],
   "source": [
    "queries = [\n",
    "    #\"What are some of the made-up characters impersonated by Michael Scott? Give a oneliner description for each character.\",\n",
    "    #\"Who is the character that is known for his 'That's what she said' jokes in The Office?\",\n",
    "    #\"Which character loves cats?\",\n",
    "    #\"A character has a heart attack in an episode of the show. Who is it?\",\n",
    "    #\"What character lives proudly on a farm?\",\n",
    "    #\"What happens to Kevin's Famous Chili when he brings it to the office?\",\n",
    "    #\"Why did Michael Scott play the Savannah murder game?\",\n",
    "    #\"How many marriages are in the show?\",\n",
    "    \"Hvad dækker P, L, A, C og E over i PLACE-akronymet af John Ziman over?\"\n",
    "]\n",
    "\n",
    "query = queries[-1]\n",
    "\n",
    "response = query_engine.query(query)\n",
    "display(Markdown(f\"{response}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce99b7d",
   "metadata": {},
   "source": [
    "## Simplest RAG implementation using LlamaIndex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e7c5c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cceb724b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AzureOpenAIEmbedding' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 10\u001b[0m\n\u001b[0;32m      1\u001b[0m llm \u001b[38;5;241m=\u001b[39m AzureOpenAI(\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m#model=\"gpt-4\",\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m#deployment_name=\"gpt-4\",\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      6\u001b[0m     azure_endpoint\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAZURE_OPENAI_ENDPOINT\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# You need to deploy your own embedding model as well as your own chat completion model\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m embed_model \u001b[38;5;241m=\u001b[39m \u001b[43mAzureOpenAIEmbedding\u001b[49m(\n\u001b[0;32m     11\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-embedding-ada-002\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     12\u001b[0m     deployment_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-embedding-ada-002\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     13\u001b[0m     api_key\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m),  \n\u001b[0;32m     14\u001b[0m     api_version\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_VERSION\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;66;03m# https://learn.microsoft.com/en-us/azure/ai-services/openai/reference?WT.mc_id=AZ-MVP-5004796\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     azure_endpoint\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAZURE_OPENAI_ENDPOINT\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m )\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Fetch documents\u001b[39;00m\n\u001b[0;32m     19\u001b[0m documents \u001b[38;5;241m=\u001b[39m SimpleDirectoryReader(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data/docs_lands_test\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mload_data()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'AzureOpenAIEmbedding' is not defined"
     ]
    }
   ],
   "source": [
    "llm = AzureOpenAI(\n",
    "    #model=\"gpt-4\",\n",
    "    #deployment_name=\"gpt-4\",\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),  \n",
    "    api_version=os.getenv(\"OPENAI_API_VERSION\"), # https://learn.microsoft.com/en-us/azure/ai-services/openai/reference?WT.mc_id=AZ-MVP-5004796\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    ")\n",
    "\n",
    "# You need to deploy your own embedding model as well as your own chat completion model\n",
    "embed_model = AzureOpenAIEmbedding(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    deployment_name=\"text-embedding-ada-002\",\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),  \n",
    "    api_version=os.getenv(\"OPENAI_API_VERSION\"), # https://learn.microsoft.com/en-us/azure/ai-services/openai/reference?WT.mc_id=AZ-MVP-5004796\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    ")\n",
    "\n",
    "# Fetch documents\n",
    "documents = SimpleDirectoryReader('./data/docs_lands_test').load_data()\n",
    "\n",
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model\n",
    "\n",
    "# build VectorStoreIndex that takes care of chunking documents\n",
    "# and encoding chunks to embeddings for future retrieval\n",
    "index = VectorStoreIndex.from_documents(documents=documents)#, \n",
    "                                        #api_key=os.environ['OPENAI_API_KEY'],\n",
    "                                        #base_url=os.environ['AZURE_API_BASE'],\n",
    "                                        #app_url=os.environ['AZURE_OPENAI_ENDPOINT'])\n",
    "#index = VectorStoreIndex.from_documents(documents=documents, embed_model=embed_model, llm=llm, verbose=True)\n",
    "\n",
    "# The QueryEngine class is equipped with the generator\n",
    "# and facilitates the retrieval and generation steps\n",
    "query_engine = index.as_query_engine()\n",
    "\n",
    "# Use your Default RAG\n",
    "response = query_engine.query(query)\n",
    "display(Markdown(f\"{response}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "98df4bb8",
   "metadata": {},
   "outputs": [
    {
     "ename": "LicensingException",
     "evalue": "IronPDF must be licensed for development.\nPlease receive a free trial key instantly to your email by visiting:\nhttps://ironpdf.com/licensing/?utm_source=product\r\n   at IronPdf.License.kpbbda()\r\n   at IronPdf.PdfDocument.axjqme(IEnumerable`1 ralkye, TextExtractionOrder ralkyf)\r\n   at IronPdf.PdfDocument.ExtractTextFromPages(IEnumerable`1 PageIndices, TextExtractionOrder Order)\r\n   at IronPdf.PdfDocument.ExtractTextFromPage(Int32 PageIndex, TextExtractionOrder Order)\r\n   at IronPdf.PdfDocument.ExtractTextFromPage(Int32 PageIndex)\r\n   at System.RuntimeMethodHandle.InvokeMethod(Object target, Void** arguments, Signature sig, Boolean isConstructor)\r\n   at System.Reflection.MethodBaseInvoker.InvokeDirectByRefWithFewArgs(Object obj, Span`1 copyOfArgs, BindingFlags invokeAttr)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLicensingException\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m pdf \u001b[38;5;241m=\u001b[39m PdfDocument\u001b[38;5;241m.\u001b[39mFromFile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/jach/Documents/JacobsDocs/KU/VtDat/Tekster/Uge3/Kuhn_objektivitet.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Extract text from specific page in the document\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m page_text \u001b[38;5;241m=\u001b[39m \u001b[43mpdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mExtractTextFromPage\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mLicensingException\u001b[0m: IronPDF must be licensed for development.\nPlease receive a free trial key instantly to your email by visiting:\nhttps://ironpdf.com/licensing/?utm_source=product\r\n   at IronPdf.License.kpbbda()\r\n   at IronPdf.PdfDocument.axjqme(IEnumerable`1 ralkye, TextExtractionOrder ralkyf)\r\n   at IronPdf.PdfDocument.ExtractTextFromPages(IEnumerable`1 PageIndices, TextExtractionOrder Order)\r\n   at IronPdf.PdfDocument.ExtractTextFromPage(Int32 PageIndex, TextExtractionOrder Order)\r\n   at IronPdf.PdfDocument.ExtractTextFromPage(Int32 PageIndex)\r\n   at System.RuntimeMethodHandle.InvokeMethod(Object target, Void** arguments, Signature sig, Boolean isConstructor)\r\n   at System.Reflection.MethodBaseInvoker.InvokeDirectByRefWithFewArgs(Object obj, Span`1 copyOfArgs, BindingFlags invokeAttr)"
     ]
    }
   ],
   "source": [
    "\n",
    "from ironpdf import *\n",
    "\n",
    "# Load existing PDF document\n",
    "pdf = PdfDocument.FromFile(\"C:/Users/jach/Documents/JacobsDocs/KU/VtDat/Tekster/Uge3/Kuhn_objektivitet.pdf\")\n",
    "\n",
    "# Extract text from specific page in the document\n",
    "page_text = pdf.ExtractTextFromPage(1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
